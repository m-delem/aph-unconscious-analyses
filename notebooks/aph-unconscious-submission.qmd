---
title: "Are there unconscious visual images in aphantasia? Development of an implicit priming paradigm"

authors:
  - name: Rudy Purkart
    orcid: 0000-0002-5491-9958
    equal-contributor: true
    affiliations:
      - name: Centre de Recherche de l’Institut Universitaire de Gériatrie de Montréal (CRIUGM), Université de Montréal
        city: Montreal
        state: Quebec
        country: Canada
  - name: Maël Delem
    orcid: 0009-0005-8518-1991
    affiliations:
      - ref: emc
    equal-contributor: true
  - name: Eddy Cavalli
    orcid: 0000-0003-3944-1973
    affiliations:
      - ref: emc
  - name: Virginie Ranson
    affiliations:
      - ref: emc
  - name: Charlotte Andrey
    affiliations:
      - ref: emc
  - name: Rémy Versace
    orcid: 0000-0002-4219-6617
    affiliations:
      - ref: emc
  - name: Gaën Plancher
    orcid: 0000-0002-0178-6207
    affiliations:
      - ref: emc
      - name: Institut Universitaire de France (IUF)
        city: Paris
        country: France
    email: gaen.plancher@univ-lyon2.fr
    corresponding: true

affiliations:
  - id: emc
    name: Laboratoire d’Étude des Mécanismes Cognitifs (EA 3082), Université Lumière Lyon 2
    city: Lyon
    country: France

format: 
  docx:
    reference-doc: custom-reference-doc.docx
  elsevier-pdf:
    journal:
      cite-style: authoryear
number-sections: true
number-depth: 3
tbl-cap-location: bottom

# filters:
#   - authors-block

abstract: For some people the experience of visual imagery is lacking, a condition recently referred to as aphantasia. So far, most of the studies on aphantasia rely on subjective reports, leaving the question of whether mental images can exist without reaching consciousness unresolved. In the present study, the formation of mental images was estimated in individuals with aphantasia without explicitly asking them to generate mental images. 151 Participants performed an implicit priming task where a probe is assumed to automatically reactivate a mental image. An explicit priming task, where participants were explicitly required to form a mental image after a probe, served as a control task. While control participants showed a priming effect in both the implicit and explicit tasks, aphantasics did not show any priming effects. These results suggest that aphantasia relies on a genuine inability to generate mental images rather than on a deficit in accessing these images consciously. Our priming paradigm might be a promising tool for characterizing mental images without relying on participant introspection.
bibliography: references.bib
# suppress-bibliography: true
csl: apa.csl
keywords: 
  - Aphantasia 
  - visual imagery 
  - sensory priming
---

::: {.content-hidden when-format="pdf"}
**Keywords**: Aphantasia, visual imagery, sensory priming
:::

{{< pagebreak >}}

# Introduction

Close your eyes and try to mentally visualize your breakfast table as you sat down to it this morning. Most people would report having a clear image of the scene in their "*mind's eye*": this experience is referred to as visual imagery, commonly defined as the experience of visual sensory information without a direct external stimulus [@pearson_human_2019]. Nonetheless, there are great differences between individuals concerning the vividness of these images, some people even declaring that they have no visual mental images at all. This extreme phenomenon, although already observed in the $19^{th}$ century [@galtonSTATISTICSMENTALIMAGERY1880] and noted in various studies since then [e.g., @fawConflictingIntuitionsMay2009; @mckelvieVVIQPsychometricTest1995; @paivioImageryAbilityVisual1971; @sheehanUnderstandingVariabilityImagery1987; @slatterAlphaRhythmsMental1960 among many others], received renewed attention only nine years ago, when @zemanLivesImageryCongenital2015, in a study that has since become very popular, coined the term "*aphantasia*" to refer to the inability to generate mental images.

Early estimates suggest that aphantasia could concern 3-4% of the global population [see for instance @dancePrevalenceAphantasiaImagery2022; @palermoCongenitalLackExtraordinary2022; @dawesCognitiveProfileMultisensory2020]. However, many aphantasics may be unaware of their condition, suggesting a potential underestimation of the phenomenon [@fawConflictingIntuitionsMay2009; @zemanPhantasiaPsychologicalSignificance2020]. Aphantasics often report reduced or absent sensory imagery in various modalities, fewer and less rich dreams [@dawesCognitiveProfileMultisensory2020], reduced episodic and autobiographical memory [@dawesCognitiveProfileMultisensory2020; @zemanPhantasiaPsychologicalSignificance2020], yet with intact spatial imagery [@zemanLivesImageryCongenital2015; @dawesCognitiveProfileMultisensory2020; @bainbridgeQuantifyingAphantasiaDrawing2021; @keoghBlindMindNo2018]. Although self-reports by aphantasics are very consistent across studies, many authors stress the need to cross subjective reports with more objective tasks assessing visual imagery. This need is highlighted by the heterogeneity and complexity of aphantasia: for example, some aphantasics report visual mental imagery when dreaming, some have preserved mental imagery in other sensory modalities, while others report a complete absence of conscious mental imagery, both voluntary and involuntary [@dawesCognitiveProfileMultisensory2020; @zemanPhantasiaPsychologicalSignificance2020]. In light of this, a reliable measurement of visual imagery would be a valuable tool to better define the condition. Yet a crucial question for this assessment is still being debated: is aphantasia a genuine absence of mental images, or do aphantasics have them but are simply unable to access them consciously?

Some researchers doubt that mental imagery could be completely absent, and have hypothesized that aphantasics who report having no conscious imagery at all might still have *unconscious* mental imagery [@nanay_unconscious_2020]. As this phenomenon is difficult to identify, little is known about unconscious mental imagery in aphantasia. A recent study by [@liuProbingUnimaginableImpact2023] used a behavioural task to assess visual imagery in various domains (the French Perception-Imagination Battery) in aphantasics and controls. The task consisted of mentally comparing pairs of items based on various features (e.g., "beaver" - "fox": which is the *longest*?). They found no differences in accuracy between the groups, but slower RTs and lower confidence in the aphantasics' answers, and argued that this result was consistent with aphantasics having the visual images required to complete the task, albeit without conscious access to them. Similarly, in a task that supposedly required visual imagery to verify whether a target dot was inside the boundaries of a previously presented geometric shape, @jacobsVisualWorkingMemory2018 found no difference in accuracy between an aphantasic participant and controls. This result could be interpreted as reflecting an unconscious comparison of a visual image with the stimuli perceived by the aphantasic participant, thus accrediting the existence of this unconscious type of imagery in aphantasia. However, due to the potential conscious processes at play in these behavioural tasks (with or without sensory imagery), neither study could completely rule out the hypothesis of aphantasics using strategies other than visual imagery (e.g., semantic processing, spatial imagery) to solve the tasks. This possibility, often raised in discussions about the condition, prevents from firmly concluding from these results that unconscious mental images exist in aphantasia.

On the other hand, several studies that sought to develop objective measures assessing visual imagery found behavioural and physiological differences between aphantasics and controls, such as aphantasics having no skin conductance response to frightening scenarios [@wickenCriticalRoleMental2021], no automatic pupil dilatation in reaction to imagined bright stimuli [@kayPupillaryLightResponse2022], or no priming by visual imagery [@keoghBlindMindNo2018], suggesting that aphantasics are truly unable to produce mental images. The latter priming paradigm developed by @keoghBlindMindNo2018 is particularly often cited as a promising and relatively undemanding task for objectively identifying aphantasia, and has already been used for this purpose in several subsequent studies [e.g., @keoghAttentionDrivenPhantom2020; @changImagelessImageryAphantasia2023]. In their initial study, they investigated visual imagery in aphantasics and controls using a binocular rivalry paradigm: in this task, participants were cued either with the letter “R” (for red) or the letter “G” (for green) and had to imagine one of two images, respectively a red-horizontal Gabor or a green-vertical Gabor. After rating the vividness of their mental image, they were presented with both Gabors simultaneously, one in the left eye, the other in the right, and asked to say which colour they had seen first. Their results showed that the mental visualization of the Gabors influenced the colour seen in the binocular rivalry task for control participants, but not for aphantasics. The authors interpreted this absence of priming in aphantasia as a real inability to generate mental images, and not just as a lack of metacognition skills.

While these conclusions are convincing about voluntary imagery (whether in conscious processes or not), they may prove inadequate concerning the hypothesis of involuntary and unconscious mental imagery [as outlined by @murakiInsightsEmbodiedCognition2023]. A first caveat in this study is that self-diagnosed aphantasics were explicitly asked to voluntarily form mental images and rate their vividness during the task. This aspect of their paradigm may have skewed the results from the start, as aphantasics were asked to do something they knew (or believed) they could not do in the first place. It is possible, then, that aphantasics did not fully engage with the task - or did not perform it correctly - because they firmly believed that they would fail to comply with the instructions, due to the awareness of their condition [see @cabbaiInvestigatingRelationshipsTrait2023 for evidence on demand biases in aphantasia] . Secondly, by using explicit priming, their study could not account for potential unconscious mental imagery, which is typically investigated with implicit priming tasks. Consequently, the binocular rivalry paradigm developed by [@keoghBlindMindNo2018; like other objective measures based on explicit instructions to use mental imagery, e.g., @kayPupillaryLightResponse2022; @miltonBehavioralNeuralSignatures2021] cannot exclude the possible existence of involuntary and unconscious mental images in aphantasia. We aimed to fill this gap by designing an implicit priming task that would allow us to study unconscious mental images in aphantasia.

## The present study

The objective of this study was to develop a new task inspired by the binocular rivalry used by @keoghBlindMindNo2018, including a priming task explicitly asking to use mental imagery, along with an implicit priming task specifically targeting unconscious mental imagery. Such a task would provide a novel and unprecedented behavioural method to identify the presence or absence of visual imagery and, by extension, to objectively characterize aphantasia.

To create an implicit task, the paradigm was divided into two parts: a prior association phase, and the implicit task itself. The association phase asked the participants to indicate the colour of a red horizontal Gabor or a blue vertical Gabor to implicitly memorize the colour-orientation association. In the subsequent implicit task, a red or blue coloured circle was presented as a prime before a target, which was a Gabor either congruent or incongruent with the colour seen (see @fig-protocol_asso and @fig-protocol_implicit in @sec-procedure). As previous works of our team have shown [e.g., @brunelWhenSeeingDog2013; @reyMaskWhoWasn2015; @reyWhenReactivatedVisual2018], the prime is assumed to reactivate an unconscious mental image of the associated Gabor automatically. Participants were then asked to indicate the orientation of the target. An explicit task was added for control and comparison where participants were overtly asked to produce a mental image of the Gabors before the targets. In the explicit task, like in Keogh and Pearson’s [-@keoghBlindMindNo2018] study, participants were asked to imagine one of the previous Gabors by presenting a letter (R or B) as a cue. A Gabor congruent or incongruent with the colour was then presented as a target, and participants were asked to indicate the orientation of the lines of the target.

Shorter RTs in the congruent trials compared to the incongruent ones would therefore reflect an influence of unconscious mental images, helping participants to respond faster. Moreover, to ensure that any priming observed would be the consequence of mental imagery (as opposed to semantic priming, for example), in half of the trials the targets were presented in black and white rather in than colour. If aphantasia relies only on a difficulty to access mental images, a priming effect should be observed for both groups in the implicit task, but not in the explicit one. If aphantasia relies on a genuine difficulty in creating mental images, no priming effect should be observed for the aphantasia group neither in the implicit nor in the explicit task, as opposed to the control group.

In addition, we carried out a second analysis with a subset of our sample composed solely of aphantasics with a minimal VVIQ score of 16, matched with controls with the highest VVIQ scores. This analysis aimed at answering a frequent interrogation in aphantasia literature about subgroups in aphantasia with differing characteristics: several authors pointed out that the fact of reporting *completely absent* imagery could be qualitatively very distinct from having only *vague* images [e.g., @blomkvistDefiningDiagnosingAphantasia2023; @dancePrevalenceAphantasiaImagery2022; @murakiInsightsEmbodiedCognition2023; @liuProbingUnimaginableImpact2023]. The object of our study, unconscious mental images, is a difficult phenomenon to reach, so this additional analysis could be crucial to judge the effects of our paradigm.

Finally, to assess the potential of this paradigm as a predictive tool for visual imagery ability, we performed correlations between the self-report questionnaires and the magnitude of the priming effect. If this effect is related to the generation of mental images, a clear association should arise between a greater priming effect and higher visual imagery ability.

# Methods

## Participants

We compared a group of self-identified aphantasic individuals with a control group of individuals with self-reported intact visual imagery. Participants were recruited from Facebook online community platforms dedicated to aphantasia in France using a recruitment ad. 151 participants completed the study. All completed an online version of the French Vividness of Visual Imagery Questionnaire [VVIQ-F, @santarpiaEvaluerVivaciteImages2008; adapted from @marksVividnessVisualImagery1973]: aphantasic participants were identified as the ones with a total VVIQ score below 32, which is the conventional threshold used in most studies on aphantasia [e.g., @danceWhatLinkMental2021; @danceWhatRelationshipAphantasia2021; @dawesCognitiveProfileMultisensory2020; @zemanLivesImageryCongenital2015]. 89 participants were in the aphantasic group ($M_{age} = 34.7, \ SD_{age} = 10.6, \ range_{age} = [19;59], \ M_{VVIQ} = 19.2, \ SD_{VVIQ} = 4.6, \ range_{VVIQ} = [16;31.5]$, 65 women) and 62 in the control group ($M_{age} = 33.2, \ SD_{age} = 9.7, \ range = [18;65], \ M_{VVIQ} = 54.5, \ SD_{VVIQ} = 12.3, \ range = [32;78.5]$, 31 women). All participants reported no lesions or acquired neurological or psychiatric disorders and no impaired or uncorrected vision.

The study was carried out following the recommendations of the French Law (Loi Jardé n◦2012- 300) with written informed consent being obtained from all the participants following the Declaration of Helsinki.

## Questionnaires

### Vividness of Visual Imagery Questionnaire - French adaptation (VVIQ-F)

The French version of the VVIQ [VVIQ-F, @santarpiaEvaluerVivaciteImages2008; adapted from @marksVividnessVisualImagery1973] used in this study was adapted in a Google Form version. It consists of sixteen items, each asking participants to imagine a particular scene and rate the vividness of their mental imagery using a Likert scale ranging from 1 ("No image at all, you only know that you are thinking about the object”) to 5 ("Perfectly clear and vivid as if it were a normal vision").

### Spontaneous use of imagery scale (SUIS)

The French version of the SUIS [SUIS-F, @ceschiImagerieMentalePsychotherapie2018; adapted from @reisbergVisualMemoryWhen1986] used in this study was adapted in a Google Form version. It consists of 12 items, each asking participants to rate the degree to which a spontaneous use of mental imagery in a particular situation is appropriate to them using a Likert scale ranging from 1 (“Never appropriate”) to 5 (“Completely appropriate”). The final score is ranging from 12 to 60.

### Object and spatial imagery questionnaire (OSIQ)

The French version of the OSIQ [Dutriaux, unpublished, adapted from @blazhenkovaObjectspatialImageryNew2006] used in this study was adapted in a Google Form version. It consists of 30 items, half of the items (i.e., 15 items) are used to assess participants’ ability to imagine an object’s shape, texture, and colour (object imagery score), and the other half (i.e., 15 items) are used to assess participants’ ability to imagine location, movements, and spatial relationships (spatial imagery score). For each item, participants rate the degree to which they agree with the statement using a Likert scale ranging from 1 (“Totally disagree”) to 5 (“Totally agree”).

## Stimuli

### Gabor patterns

Four Gaussian-shaped Gabor patterns were generated: one red Gabor with horizontal lines and one blue Gabor with vertical lines (coloured Gabors); one black Gabor with horizontal lines and one black Gabor with vertical lines (uncoloured Gabors). All Gabor were superposed on a white 160 $\times$ 160 pixels background.

### Cues

Two cues were generated: a red circle and a blue circle. Both were of the same size as the Gabor patterns and were superposed on a white 160x160 pixels background.

## Software

The tasks were programmed using OpenSesame [@mathotOpenSesameOpensourceGraphical2012] and were uploaded on Jatos [@langeJustAnotherTool2015], a server used to run experiments online. All the experimental material is openly available on OSF (<https://osf.io/635dv/?view_only=7ddddbf7e19a443db86d73dca66734e2>).

## Procedure {#sec-procedure}

Participants were provided with two links, one directing to the experiments, and one directing to the questionnaire. They were instructed to perform the experiments and the questionnaires alone, in a quiet and not distracting environment, and to turn off their phones and other messaging devices. They were also asked to use a computer with a keyboard, as well as a good internet connection. Once participants clicked on the link to the experiments, the first experimental task launched.

![***Associative task.*** A fixation cross (500 ms) is followed by one of the two coloured Gabor. Participants had to indicate the colour of the Gabor by pressing the corresponding key (either R for Red or B for Blue), without time constraint. Each Gabor was presented 50 times.](figures/protocol_asso.png){#fig-protocol_asso}

Participants began with the implicit priming task. This task began with an associative phase (@fig-protocol_asso) in which a fixation cross (500 ms) was followed by one of the two coloured Gabor, and participants had to indicate the colour of the Gabor by pressing the corresponding key (either R for Red or B for Blue), without time constraint. Each Gabor was presented 50 times. After the association phase, participants started the implicit priming test phase (@fig-protocol_implicit) in which a fixation cross (500 ms) was followed by a cue (150 ms) that was either a red or a blue circle, and then depending on the condition by either one of the two coloured Gabor or by one of the uncoloured Gabor, as a target. Participants had to indicate the orientation of the Gabor’s lines by pressing the corresponding key (either H for horizontal, or V for vertical), using only their dominant hand. In the congruent condition, the cue has the same colour as the target Gabor (coloured condition) or primed the Gabor with the same line orientation as the black target Gabor (uncoloured condition), contrary to the non-congruent condition. There were 16 trials per congruence and colour pairs, amounting to 64 trials total for the task.

![***Implicit priming task.*** A fixation cross (500 ms) is followed by a cue (150 ms) that was either a red or a blue circle, and then by one of the two coloured Gabor, or by one of the uncoloured Gabor, as a target. Participants had to indicate the orientation of the Gabor’s lines by pressing the corresponding key (either H for horizontal, or V for vertical), using only their dominant hand.](../figures/protocol_implicit.png){#fig-protocol_implicit}

After the implicit priming task and a short break, participants transitioned to the explicit task (@fig-protocol_explicit) in which a fixation cross (500 ms) was followed by a letter as a cue (1500 ms) that was either the letter R (for red) or B (for blue). In response to the cue, participants were asked to form a mental imagery of the corresponding Gabor (a red with horizontal lines or a blue with vertical lines) and to keep that image in mind during 3000 ms while fixing the centre of a blank screen. Then, a fixation cross (500 ms) was presented followed by one of the two coloured Gabor, or by one of the uncoloured Gabor, and participants had to indicate the orientation of the Gabor’s lines by pressing the corresponding key (either H for horizontal, or V for vertical), using only their dominant hand. In the congruent condition, the cue designated the same colour as the target Gabor (coloured condition) or primed the Gabor with the same line orientation as the black target Gabor (uncoloured condition), contrary to the non-congruent condition. Likewise, there were 16 trials per congruence and colour pairs, amounting to 64 trials total for the task. It is worth mentioning that participants had practice trials at the beginning of each task and phase. Moreover, the implicit priming task was divided into two blocks, each beginning with the association phase, and ending with the implicit priming phase, to preserve the association between the colour of the Gabor and the orientation of its lines.

![***Explicit priming task.*** A fixation cross (500 ms) was followed by a letter as a cue (1500 ms) that was either the letter R (for red) or B (for blue). In response to the cue, participants were asked to form a mental imagery of the corresponding Gabor (a red with horizontal lines or a blue with vertical lines) and to keep that imagery in mind during 3000 ms while fixing the centre of a blank screen. Then, a fixation cross (500 ms) was presented followed by one of the two coloured Gabor, or by one of the uncoloured Gabor, and participants had to indicate the orientation of the Gabor’s lines by pressing the corresponding key (either H for horizontal, or V for vertical), using only their dominant hand.](../figures/protocol-explicit.png){#fig-protocol_explicit}

## Analyses

The data analysis was programmed in R language [version 4.2.0, @r2022] on RStudio [@rstudio2023]. The raw data, code, and analysis outputs are available on OSF (<https://osf.io/635dv/?view_only=7ddddbf7e19a443db86d73dca66734e2>).

### Self-report questionnaires

The scores of the four questionnaires were modelled with Generalized Linear Models (GLMs) to accommodate the non-normal distributions of several questionnaires (mostly bi-modal distributions due to our two groups) and to control for the influence of age on the group differences. The GLMs were fitted with Gamma distributions, chosen as the best one against Gaussian and inverse Gaussian distributions fitted and compared using the Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC). The models included the *Group* as a categorical predictor and the *Age* as a continuous covariate. For group differences, we report estimated means, their standard errors, and two-tailed *p*-values of marginal contrasts between means, computed using a Wald *t*-distribution approximation.

### Response times

#### Outlier detection procedure

For the analysis of reaction times (RTs), we excluded data from five participants that exceeded 43% of errors (therefore with too few trials to analyse). Incorrect responses were then removed (2.7% and 3.6% of trials in the implicit/explicit task respectively), along with RTs abnormally fast or slow ($<$ 250ms or $>$ 3s, 1% and .7% respectively) that could represent false alarms (especially given the internet-based nature of the task). Participants with an aberrant RT average exceeding the median $\pm 3 \times$ MAD were excluded for each task [MAD proved to be more robust than standard deviations for outlier detection, see @leysDetectingOutliersNot2013]. The remaining RT data comprised N = 8777 trials for the implicit and N = 8603 trials for the explicit task.

#### Power analysis

As the experiment was conducted online, the sample size was mostly limited by the time resources of the project. Likewise, the number of trials per condition and the total amount of trials were balanced in order not to overload the Internet experiment. From these two constraints, we estimated the statistical power conferred by the sample size eventually reached and the experimental design *a priori*, i.e. based on effect sizes reported in the literature and our hypotheses. We used the *simr* package [@greenSIMRPackagePower2016] to simulate datasets reflecting the experimental design, featuring expected patterns of means and variance, and fitting generalized linear mixed models on them.

Common effect sizes reported in the literature and intra-individual trial-to-trial variability in RTs in perceptual discrimination tasks have been used to simulate data and estimate the statistical power to detect effects tied to experimental conditions [for a similar procedure, see @fucciReadyHelpNo2023]. The main effect of interest chosen was the interaction between Group and Congruence, where we hypothesized a reduction in RTs for the control group in the congruent condition that would not be present in aphantasics. Simulations have shown that the statistical power reached 80% even with little effect sizes nearing 24ms, and exceeded 90% when the effect size went up and above 30ms. Details of the procedure can be found in the extended analysis report on OSF (<https://osf.io/635dv/?view_only=7ddddbf7e19a443db86d73dca66734e2>).

#### Generalized Linear Mixed Models

To account for the non-normal, positively skewed distributions of the RTs, we fitted Generalized Linear Mixed Models (GLMMs) with inverse Gaussian distributions, as recommended by @loTransformNotTransform2015. The models were implemented in the lme4 R package [@bates2014fitting]. Models with Gamma and Gaussian distributions were also fitted and compared with the AIC and BIC to ensure that we chose the best distribution available.

The models included the *Group* (aphantasic, control), *Congruence* condition (congruent or incongruent), and *Colour* condition (colour or uncoloured) along with all their two and three-way interactions as fixed categorical predictors, while *participants* have been included as grouping factors (i.e. "random effects"). Complex random-effects structures including various slopes on the factors failed to converge to stable and reliable estimates, hence the optimal models chosen included a single by-participant random intercept.

Due to the way that variance is partitioned in linear mixed models [@rightsQuantifyingExplainedVariance2019], there does not exist an agreed-upon way to calculate standard effect sizes for individual terms such as main effects or interactions in these models. Thus, in line with general recommendations on how to report effect sizes [e.g., @pekReportingEffectSizes2018], we report and analyse unstandardised effect sizes for post-hoc tests in the form of estimated marginal contrasts in milliseconds (i.e. differences in model-estimated marginal means) where appropriate.

#### Correlation analyses

Pearson correlation coefficients were computed to assess the linear relationship between each questionnaire score and the *congruence effects* in both tasks. The congruence effect was computed for each participant as the difference between the mean RT in the incongruent condition minus the mean RT in the congruent condition, first averaging across colour conditions to account for this factor.

# Results

## Self-report questionnaires

![Visualization of self-report questionnaires results for aphantasics and controls. Violin plots depict the distributions and quantiles of the scores in each group, median-centred on each scale. Coloured dots depict standardized means of the scores to the questionnaires, while the solid lines represent their standard errors. On the vertical axis, 0.0 is the normalized lowest possible score, 0.5 is the median score, and 1 is the maximum possible score for each questionnaire. Stars denote *p*-values inferior to .001 for each pairwise contrast between groups.](figures/00-plot-questionnaires.png){#fig-plot_questionnaires}

As expected, aphantasic participants reported significantly less visual imagery across questionnaires (see @fig-plot_questionnaires), scoring below controls on the VVIQ ($M_{Aph.}$ = 19.20 $\pm$ .47; $M_{Controls}$ = 54.39 $\pm$ 1.61; *t*(147) = 24.23, *p* $< .001$), the SUIS ($M_{Aph.}$ = 17.31 $\pm$ .44; $M_{Controls}$ = 37.07 $\pm$ 1.13; *t*(147) = 18.35, *p* $< .001$) and the object scale of the OSIQ ($M_{Aph.}$ = 23.90 $\pm$ .65; $M_{Controls}$ = 46.50 $\pm$ 1.52; *t*(147) = 15.19, *p* $< .001$). Surprisingly, aphantasics scored significantly lower than controls on the spatial scale of the OSIQ ($M_{Aph.}$ = 40.98 $\pm$ .83; $M_{Controls}$ = 45.59 $\pm$ 1.10; *t*(147) = 3.41, *p* $< .001$), a result contrasting with previous studies having found no between-group differences on this scale [e.g., @dawesCognitiveProfileMultisensory2020; @keoghBlindMindNo2018]. Nevertheless, this difference is much less pronounced than in other questionnaires, and there are large variations on this scale in the aphantasic group (e.g., the lowest observed score is 27/75, while the highest is 61/75).

## Response times: Conventional VVIQ groups

### Implicit task

The estimates of the model for the RTs in the implicit task yielded a significant main effect of Congruence ($\beta$ = .03, *SE* = .008, 95% CI \[ -.01, .04\], *t*(8767) = 2.91, *p* = .004) and a significant interaction between Group and Congruence (@fig-plot-glmms, left panel; $\beta$ = -.03, *SE* = .01, 95% CI \[ -.06, -.01\], *t*(8767) = -2.93, *p* = .003). Post-hoc contrasts of marginal means showed that controls responded faster in the congruent condition (marginal contrast (controls RT congruent - incongruent) = -30ms, *SE* = 6ms, 95% CI \[ -40, -10\], *p* $< .001$). The contrast analysis also shows that the faster response of controls was driving the main effect of Congruence, as aphantasics did not respond faster in the congruent condition (marginal contrast (aphantasics RT congruent - incongruent) = -2ms, *SE* = 5ms, 95% CI \[ -10, 10\], *p* = .73). The model did not show any main effect of Group (*p* = .17) or Colour (*p* = .82), no interaction between Group and Colour (*p* = 0.43) or Congruence and Colour (*p* = 0.97), and no three-way interaction (*p* = 0.23).

![Visualizations of the interactions between Group and Congruence in the optimal models for both tasks. The coloured dots indicate the marginal means of the groups in each condition whereas the black bars represent the standard error of these estimates. The stars represent *p*-values inferior to .001 in the contrast analyses.](figures/plot-glmms-vertical.png){#fig-plot-glmms}

### Explicit task

The estimates of the model for the RTs in the explicit task yielded a significant main effect of Congruence ($\beta$ = .03, *SE* = .008, 95% CI \[.02, .05\], *t*(8593) = 3.89, *p* $< .001$) and Colour ($\beta$ = .03, *SE* = .008, 95% CI \[.02, .05\], *t*(8593) = 4.03, *p* $< .001$). The model also revealed a significant interaction between Group and Congruence (@fig-plot-glmms, right panel; $\beta$ = -.03, *SE* = .01, 95% CI \[ -.06, -.01\], *t*(8593) = -2.97, *p* = .003). Post-hoc contrasts of marginal means showed that, once again, controls responded faster in the congruent condition (marginal contrast (controls RT congruent - incongruent) = -30ms, *SE* = 6ms, 95% CI \[ -40, -20\], *p* $< .001$). Likewise, the faster response of controls was driving the main effect of Congruence, as aphantasics did not respond faster in the congruent condition either (marginal contrast (aphantasics RT congruent - incongruent) = -5ms, *SE* = 5ms, 95% CI \[ -20, 10\], *p* = .39). The main effect of Colour reflects the fact that participants responded faster overall in the coloured condition (marginal contrast (RT coloured - uncoloured) = -30ms, *SE* = 4ms, 95% CI \[ -40, -20\], *p* $< .001$), although this factor did not interact with the two others. The model did not show any main effect of Group (*p* = .47), no interaction between Group and Colour (*p* = 0.22) or Congruence and Colour (*p* = 0.74), and no three-way interaction (*p* = 0.40).

## Response times: Extremal VVIQ groups

### Implicit task

The estimates of the new model for the implicit task showed a significant main effect of Congruence ($\beta$ = .02, *SE* = .009, 95% CI \[0, .04\], *t*(5526) = 2.20, *p* = .03) and a significant interaction between Group and Congruence (@fig-plot-glmms-x, left panel; $\beta$ = -.04, *SE* = .01, 95% CI \[-.07, -.01\], *t*(5526) = -2.79, *p* = .005). Once again, the contrast analyses revealed that the effect of Congruence was driven by controls responding faster in the congruent condition (marginal contrast (controls RT congruent - incongruent) = -30ms, *SE* = 7ms, 95% CI \[-40, -10\], *p* $< .001$), as opposed to aphantasics (marginal contrast (aphantasics RT congruent - incongruent) = -6ms, *SE* = 7ms, 95% CI \[ -20, 10\], *p* .42). The model also yielded a trend main effect of Group close to statistical significance ($\beta$ = .06, *SE* = .03, 95% CI \[0, .13\], *t*(5526) = 1.93, *p* = .06) hinting that aphantasics may have responded overall slower than controls, however the contrast was not significant (marginal contrast (RT aphantasics - controls) = -40ms, *SE* = 30ms, 95% CI \[ -100, 20\], *p* = .19). There were no main effects of Colour (*p* = .57), no interaction between Group and Colour (*p* = .48) or Congruence and Colour (*p* = .30), and no triple interaction (*p* = .58).

![Visualizations of the interactions between Group and Congruence in the optimal models for both tasks with smaller groups at extreme ends of the VVIQ. The coloured dots the indicate marginal means of the groups in each condition whereas the black bars represent the standard error of these estimates. The stars represent *p*-values inferior to .001 in the contrast analyses.](figures/plot-glmms-x-vertical.png){#fig-plot-glmms-x}

### Explicit task

The estimates of the new model for the explicit task showed a significant main effect of Congruence ($\beta$ = .04, *SE* = .009, 95% CI \[.02, .06\], *t*(5442) = 4.03, *p* = $< .001$) and Colour ($\beta$ = .04, *SE* = .009, 95% CI \[.02, .05\], *t*(5442) = 3.93, *p* = $< .001$), along with a significant interaction between Group and Congruence (@fig-plot-glmms-x, right panel; $\beta$ = -.03, *SE* = .01, 95% CI \[-.06, -.01\], *t*(5442) = -2.34, *p* = .02). The contrast analyses again showed that the effect of Congruence was driven by controls responding faster in the congruent condition (marginal contrast (controls RT congruent - incongruent) = -30ms, *SE* = 7ms, 95% CI \[-50, -20\], *p* $< .001$), while aphantasics did not (marginal contrast (aphantasics RT congruent - incongruent) = 2ms, *SE* = 8ms, 95% CI \[ -10, 20\], *p* .85). Contrast analysis on the main effect of Colour showed that participants responded faster overall in the coloured condition (marginal contrast (RT coloured - uncoloured) = -30ms, *SE* = 5ms, 95% CI \[ -40, -20\], *p* $< .001$), although this factor did not interact with the two others. There were no main effects of Group (*p* = .33), no interaction between Group and Colour (*p* = .58) or Congruence and Colour (*p* = .60), and no triple interaction (*p* = .81).

## Correlations with the subjective questionnaires

+---------------------------------+---------------------+-------------------------+--------------+-------------------------+
|                                 | VVIQ                | OSIQ-Object             | OSIQ-Spatial | SUIS                    |
+=================================+=====================+=========================+==============+=========================+
| Implicit task congruence effect | *r* = .15           | ***r*** **= .21**       | *r* = .08    | ***r*** **= .21**       |
|                                 |                     |                         |              |                         |
|                                 | *p* = $.07^{\cdot}$ | ***p*** **=** $.01^{*}$ | *p* = .36    | ***p*** **=** $.01^{*}$ |
+---------------------------------+---------------------+-------------------------+--------------+-------------------------+
| Explicit task congruence effect | *r* = .10           | *r* = .13               | *r* = .01    | *r* = .13               |
|                                 |                     |                         |              |                         |
|                                 | *p* = .24           | *p* = .14               | *p* = .89    | *p* = .14               |
+---------------------------------+---------------------+-------------------------+--------------+-------------------------+

: Matrix of the pairwise Pearson correlation coefficients between each questionnaire score and the congruence effect in both tasks. {#tbl-correlations}

Finally, Pearson correlations were computed to assess the linear relationship between the questionnaire scores and the *congruence effects* in both tasks. In the explicit task, the congruence effect was not correlated with the VVIQ (*r* = .10, *p* = .24), the OSIQ-Object (*r* = .13, *p* = .14), the OSIQ-Spatial (*r* = .01, *p* = .89), or the SUIS (*r* = .13, *p* = .14). In the implicit task however, the congruence effect correlated with the OSIQ-Object (*r* = .21, *p* = .01) and the SUIS (*r* = .21, *p* = .01), had a trend correlation with the VVIQ (*r* = .15, *p* = .07), but no correlation with the OSIQ-Spatial (*r* = .07, *p* = .14). All the pairwise correlations between the scores and the congruence effects in both tasks are presented in @tbl-correlations. The two significant correlations of the implicit task congruence effects with the OSIQ-Object and SUIS are represented in @fig-plot-corr-both.

![Visualizations of the correlation between the congruence effect (i.e. the mean difference between incongruent and congruent RTs) in the implicit task and the OSIQ-Object and SUIS scores. Aphantasics are represented with orange dots, and controls with blue triangles. All the observations are connected with a thin line to their group mean, represented as a bigger symbol. The black regression line denotes the correlation between the scores and the effect, independently of groups, along with its confidence interval.](figures/plot-corr-both.png){#fig-plot-corr-both}

# Discussion

The objective of the present study was to examine whether aphantasics could form mental images but could not access them consciously, or whether they presented a genuine deficit in the generation of mental images. To this end, we built and tested implicit and explicit priming paradigms on aphantasic and control participants. Analyses revealed striking evidence that the control group showed a consistent congruence effect in both tasks, whereas the aphantasic group did not. The intensive study of Gabors in a preliminary association should have facilitated the decision for Gabors congruent with the prime, as demonstrated in the control group, an effect that can be interpreted as the influence of an unconscious mental image of the studied Gabors. However, this effect was not observed in the aphantasic group. This result was also present when adopting a more conservative definition of aphantasia by analysing groups restricted to aphantasics scoring at floor VVIQ and controls with high VVIQ scores. This result supports the hypothesis that aphantasia may be associated with a reduction or absence of mental image generation, *even unconscious*, as opposed to a lack of conscious access to mental images.

## Towards an objective assessment of aphantasia

The priming task developed in the present study proved to be efficient to discriminate between groups of visual imagery ability, both when implemented with explicit instructions to use imagery and when implemented with implicit priming. The explicit task with instructions to produce mental imagery was inspired by the binocular rivalry paradigm developed by @keoghBlindMindNo2018 and managed to replicate their pattern of results showing an absence of priming in aphantasia, thus validating the effectiveness of priming tasks to evidence conscious mental imagery differences. However, the main aim of our study was to go one step further and develop a task that could evidence mental imagery differences *without* relying on instructions to produce it. Thus, the implicit priming task developed here was designed to target specifically unconscious mental imagery without giving participants instructions. The results of this task consistently followed the same pattern as the explicit task, lending credence to the hypothesis that the implicit task involved an unconscious form of mental imagery. We argue that this novel paradigm provides a strong base to develop implicit objective behavioural assessments of visual imagery, thereby opening promising avenues for a better objective characterization of aphantasia.

The correlations of the congruence effect in the implicit task with the OSIQ-Object scale and the SUIS further demonstrate the potential of our paradigm to assess individual differences in visual imagery. Results have shown a continuous increase of the implicit congruence effect with increasing visual imagery, supporting that implicit tasks may have the potential to assess visual imagery as a continuum, as opposed to relying on group comparisons. Future work investigating implicit behavioural effects which are correlated with visual imagery and observed at a *by-participant* level will be crucial to further ascertain results on aphantasia and individual differences in mental imagery. The consistency of the congruence effect correlations with the OSIQ-Object and the SUIS also highlights that the VVIQ may not always be appropriate as a reference measure for visual imagery. The high similarity between the aforementioned correlations supports the idea that this association between the questionnaires and the behavioural effect is stable and indeed linked to conscious visual imagery. However, the association was much weaker with the VVIQ, and might have gone unnoticed if we only analysed this questionnaire. Contrary to the VVIQ, the SUIS and the OSIQ are more grounded into daily life (e.g., *When reading fiction, I usually form a clear and detailed mental picture of a scene or room that has been described*). It is interesting to observe that our paradigm correlates with rather ecological forms of visual imagery. In light of this result, we argue that a wider diversity of psychometric questionnaires needs to be used along with efficient behavioural tasks when studying aphantasia, to better understand the complex construct that is mental imagery.

## Unconscious mental imagery and sensorimotor simulation

A main novelty of our paradigm is that participants were not instructed to produce any specific mental content in the implicit task, thus avoiding demand bias. However, this raises the question of whether our study assessed "mental imagery", as it is commonly defined as a conscious and voluntary experience. More broadly, this raises the question of whether the concept of "unconscious" mental images is relevant. As @murakiInsightsEmbodiedCognition2023 point out, such images could neither be voluntarily produced by the participant nor consciously experienced, and are therefore by definition very hard to objectify. @murakiInsightsEmbodiedCognition2023 suggest that the idea of "unconscious mental images" could be likened to the concept of "sensorimotor simulation" developed in the field of embodied cognition. A sensorimotor simulation is the re-creation of the states in which the individual's perceptual and motor systems were in a previous experience, as well as their emotional and introspective states [e.g., @barsalouGroundedCognition2008; @barsalouSimulationSituatedConceptualization2009; @dijkstraMechanismsEmbodiment2015; @milleSensMemoire2021; @versaceContentsLongtermMemory2009; @versaceActInIntegratedView2014; @versaceCognitionIncarneeCognition2018]. From this re-creation emerges a representation that can reach consciousness in the form of a mental image of an object, if the neurons in the perceptual and motor systems that were activated during confrontations with this object are reactivated in the current situation. In support of this hypothesis, @petilliDatadrivenComputationalModels2021 have shown using implicit priming tasks that verbal cues affected subsequent processing of target words with related visual properties, even when visual processing was neither requested nor required. Various cross-modal priming studies have shown that such cues could also influence behavioural responses based on other modalities [e.g., verbal cues influencing decision tasks on images or sounds, see @brunelSensoryNatureKnowledge2010; @reyMaskWhoWasn2015; @reyAutomaticVisualSimulation2017; @valletPerceptualNatureCrossModal2010]. Similarly, @amitAsymmetricalRelationshipVerbal2017 have provided evidence that feature representations are generated in visual cortices during verbal cues, even in decision tasks based on verbal processing. This evidence supports the idea that multimodal sensory representations emerge in priming tasks and influence behaviour. Consequently, following the association drawn by @murakiInsightsEmbodiedCognition2023 between sensorimotor simulation and unconscious mental images, our results provide evidence that the simulation of the visual (and potentially sensory in general) properties of concepts or incoming information could be reduced or absent in aphantasia.

## Alternative strategies and forms of imagery

A recurrent challenge when studying aphantasia is that many tasks that are often considered to require visual imagery could also be solved by other non-visual strategies, such as the use of internal or covert verbalization [@monzelMemoryDeficitsAphantasics2022]. In that vein, it could be argued that our tasks could be completed using a verbal or propositional strategy based on the colour of the stimuli. For instance, in the association phase, participants may have used the propositional strategy of forming the abstract or semantic representation of an association between colour and line orientation of the Gabors (e.g., by internally repeating that "blue patches have vertical lines"). During the tasks, participants could then have used such a representation when a prime was presented, which may have facilitated their response when the target's colour was congruent with the colour of the prime. However, our tasks have the decisive advantage of preventing the use of this type of strategy with a condition in which the targets are not coloured. As no semantic representations had been previously associated with uncoloured targets, a colour-based strategy was inappropriate for these stimuli. This type of strategy could even have been detrimental, which could explain slower response times in the uncoloured condition than in the coloured condition. Thus, the persistence of the interaction between group and congruence independently of the colour conditions supports the idea that our results can not be explained purely by the reliance on propositional strategies.

Curiously, the analysis of questionnaire data yielded a significant difference between aphantasics and controls in reported spatial imagery, assessed by the spatial scale of the OSIQ, contrasting with previous studies on aphantasia that used this questionnaire and found no between-group differences [@dawesCognitiveProfileMultisensory2020; @keoghBlindMindNo2018; @bainbridgeQuantifyingAphantasiaDrawing2021]. While this difference is hard to interpret on its own, it is worth noting that although significant, the difference in spatial imagery between the groups is much less pronounced than the difference observed on visual imagery scales. Large differences in spatial imagery ability also existed within the aphantasic group, hinting that this finding could be specifically tied to our sample and, more generally, that there could exist various sub-types in aphantasia characterized by their variable reliance on different forms of mental representations (e.g., spatial, verbal, kinaesthetic). Nevertheless, it should be mentioned that our paradigm relied partially on spatial judgements (namely, orientation properties of items) that might be impacted by spatial imagery abilities. This hypothesis also applies to a growing number of studies on aphantasia that used paradigms consisting in the detection of orientation changes of Gabor patches, thought to assess visual imagery or visual working memory [e.g., @changBehavioralPerformanceCortical2023; @keoghAttentionDrivenPhantom2020; @keoghBlindMindNo2018; @keoghVisualWorkingMemory2021; @knightMemoryImageryNo2022; @slinnVividnessVisualImagery2023 inter alia]. Interestingly, most of these studies found no differences in performance between aphantasics and controls. While our results did exhibit differing patterns between groups, future studies should still pay particular attention to this spatial imagery factor. On the one hand, this would require a more systematic investigation of spatial imagery, which has proved to have distinct characteristics from visual imagery in aphantasia [see @blazhenkovaTwoEyesBlind2019; @palermoCongenitalLackExtraordinary2022]. On the other hand, this entails that care should be taken to design tasks that target visual imagery as specifically as possible, manipulating item properties such as colour or shape while accounting for semantic and spatial properties of items [see e.g., @liuProbingUnimaginableImpact2023].

## Consequences on aphantasia

Finally, the functional implications of the differences in information processing found in aphantasia also need to be evaluated in the context of their "real-world" consequences. Aphantasics have demonstrated to live typical lives, most eloquently echoed by the fact that aphantasia often goes unnoticed for years [@zemanLivesImageryCongenital2015; @zemanPhantasiaPsychologicalSignificance2020]. Furthermore, it has not yet been proven that aphantasia is a pathological disorder [see @monzelNoGeneralPathological2023, @blomkvistDefiningDiagnosingAphantasia2023 for a discussion]. Thus, the finding of reduced unconscious mental imagery (or sensorimotor simulation) in aphantasia may be best interpreted as showing that these processes might not play a crucial role as previously thought, for instance on conceptual processing [see e.g., @meteyardComingAgeReview2012; @pecherBoundariesGroundingAbstract2018]. In stark contrast, it is often implied that the absence of fast automatic predictive processing and simulation of sensory representations in aphantasia could be a major functional disadvantage [see for instance @monzelMemoryDeficitsAphantasics2022; @blomkvistDefiningDiagnosingAphantasia2023], therefore framing the condition as mostly characterized by deficits and drawbacks. Nonetheless, couldn't an absence of strong unconscious priming by internal representations be beneficial? Several recent studies suggest that this attenuation of internal sensory representations in aphantasia could have positive consequences: @wickenCriticalRoleMental2021 showed that aphantasics exhibited dimmed electrophysiological responses to frightening scenarios; @keoghFewerIntrusiveMemories2023 used a laboratory model of PTSD and noted that aphantasics reported fewer intrusive memories when confronted with traumatic films; @konigsmarkGanzflickerExperienceHigh2021 demonstrated, using a rhythmic flicker paradigm to induce pseudo-hallucinations, that aphantasics experienced less anomalous percepts. In the present study we have brought evidence suggesting that aphantasics simulate less sensory elements in their unconscious representations. The potential positive consequences of this reduction in sensory simulation in aphantasia is an interesting topic that deserves further research. This could shed new light on this condition and help to define aphantasia as a balanced state rather than a disorder.

## Conclusion

In sum, our findings provided evidence suggesting that aphantasia does not only result from lacking metacognition but might reflect an actual alteration (whether a reduction or an absence) of both conscious and unconscious mental imagery. The consistency of the congruence effects obtained in our implicit and explicit tasks also shows that this priming paradigm is a promising and reliable basis for developing future behavioural tasks aiming to characterize unconscious mental imagery objectively and implicitly, without relying on participant introspection.

# Data and code availability {.unnumbered}

All the materials and implementations of the questionnaires and tasks, the full anonymised data set, analysis scripts and results, and a complete reproducible analysis report, are all freely available on the Open Science Framework (<https://osf.io/635dv/?view_only=7ddddbf7e19a443db86d73dca66734e2>).

# Author contributions {.unnumbered}

**Conceptualization**: RP, EC, VR, CA, RV, GP. **Data curation**: RP, MD, VR. **Formal analysis**: MD. **Funding acquisition**: GP, EC. **Investigation**: VR, CA. **Methodology**: RP, EC, VR, CA, RV, GP. **Project administration**: GP, EC. **Resources**: VR, CA, GP. **Software**: MD. **Supervision**: GP, EC. **Visualization**: MD. **Writing - Original Draft Preparation**: RP, MD, EC, VR, GP. **Writing - Review & Editing**: All authors.

# Declaration of interest {.unnumbered}

None.

{{< pagebreak >}}

# References {.unnumbered}

::: {#refs}
:::

---
title: "Are there unconscious visual images in aphantasia? Development of an implicit priming paradigm"
abstract: For some people the experience of visual imagery is lacking, a condition recently referred to as aphantasia. So far, most of the studies on aphantasia rely on subjective reports, leaving the question of whether mental images can exist without reaching consciousness unresolved. In the present study, the formation of mental images was estimated in individuals with aphantasia without explicitly asking them to generate mental images. 151 Participants performed an implicit priming task where a probe is assumed to automatically reactivate a mental image. An explicit priming task, where participants were explicitly required to form a mental image after a probe, served as a control task. While control participants showed a priming effect in both the implicit and explicit tasks, aphantasics did not show any priming effects. These results suggest that aphantasia relies on a genuine inability to generate mental images rather than on a deficit in accessing these images consciously. Our priming paradigm might be a promising tool for characterizing mental images without relying on participant introspection.
keywords: 
  - Aphantasia 
  - visual imagery 
  - sensory priming
author: 
  - name: Rudy Purkart
    orcid: 0000-0002-5491-9958
    equal-contributor: true
    affiliations:
    - ref: emc
    - id: criugm
      name: Research Center of the Institut Universitaire de Gériatrie de Montréal (CRIUGM)
      city: Montreal
      state: Quebec
      country: Canada
      url: https://www.criugm.qc.ca
  - name: Maël Delem
    orcid: 0009-0005-8518-1991
    equal-contributor: true
    affiliations:
    - id: emc
      name: Study of Cognitive Mechanisms (EMC) Laboratory
      city: Lyon
      country: France
      url: https://emc.univ-lyon2.fr
  - name: Eddy Cavalli
    orcid: 0000-0003-3944-1973
    affiliations:
    - ref: emc
  - name: Virginie Ranson
    affiliations:
    - ref: emc
  - name: Charlotte Andrey
    affiliations:
    - ref: emc
  - name: Rémy Versace
    orcid: 0000-0002-4219-6617
    affiliations:
    - ref: emc
  - name: Gaën Plancher
    orcid: 0000-0002-0178-6207
    affiliations:
    - ref: emc
    - id: iuf
      name: Institut Universitaire de France (IUF)
      city: Paris
      country: France
      url: https://www.iufrance.fr
    email: gaen.plancher@univ-lyon2.fr
    corresponding: true
format:
  docx: 
    reference-doc: "../utils/docx/custom-reference-doc-numbered.docx"
---

::: {.content-hidden when-format="pdf"}
**Keywords**: Aphantasia, visual imagery, sensory priming
:::

<!-- Different versions of the manuscript to build: -->

<!--  1. Full manuscript + title + abstract (automatically generated) -->

<!--  2. Manuscript anonymised (no title page, remove author contributions) -->

<!--  3. Title page -->

<!--  4. Title page with authors only -->

<!--  5. References only -->

{{< pagebreak >}}

# Introduction

Close your eyes and try to mentally visualize your breakfast table as you sat down to it this morning. Most people would report having a clear image of the scene in their "*mind's eye*": this experience is referred to as visual imagery, commonly defined as the experience of visual sensory information without a direct external stimulus [@pearson_human_2019]. Nonetheless, there are great differences between individuals concerning the vividness of these images, some people even declaring that they have no visual mental images at all. This extreme phenomenon, although already observed in the $19^{th}$ century [@galton1880] and noted in various studies since then [e.g., @farahCaseStudyMental1988; @fawConflictingIntuitionsMay2009; @marksVisualImageryDifferences1973; @mckelvieVVIQPsychometricTest1995; @paivioImageryAbilityVisual1971; @sheehanUnderstandingVariabilityImagery1987; @slatterAlphaRhythmsMental1960], received renewed attention only nine years ago, when @zemanLivesImageryCongenital2015 published [a study that has since been highly cited]{bg-colour="#FFFF00"}, coining the term "*aphantasia*" to refer to "[reduced or absent voluntary imagery]{bg-colour="#FFFF00"}".

Early estimates suggest that aphantasia could concern 3-4% of the global population [see for instance @dancePrevalenceAphantasiaImagery2022; @palermoCongenitalLackExtraordinary2022; @dawesCognitiveProfileMultisensory2020]. However, many people with aphantasia may be unaware of it, suggesting a potential underestimation of the phenomenon [@fawConflictingIntuitionsMay2009; @zemanPhantasiaPsychologicalSignificance2020]. Aphantasics often report reduced or absent sensory imagery in various modalities, fewer and less rich dreams [@dawesCognitiveProfileMultisensory2020], reduced episodic and autobiographical memory [@dawesCognitiveProfileMultisensory2020; @zemanPhantasiaPsychologicalSignificance2020], yet with intact spatial imagery [@zemanLivesImageryCongenital2015; @dawesCognitiveProfileMultisensory2020; @bainbridgeQuantifyingAphantasiaDrawing2021; @keoghBlindMindNo2018]. Although self-reports by aphantasics are very consistent across studies, many authors stress the need to cross subjective reports with more objective tasks assessing visual imagery. This need is highlighted by the heterogeneity and complexity of aphantasia: for example, some aphantasics report visual mental imagery when dreaming, some have preserved mental imagery in other sensory modalities, while others report a complete absence of conscious mental imagery, both voluntary and involuntary [@dawesCognitiveProfileMultisensory2020; @zemanPhantasiaPsychologicalSignificance2020]. In light of this, a reliable measurement of visual imagery would be a valuable tool to better define aphantasia. Yet a crucial question for this assessment is still being debated: is aphantasia a genuine absence of mental images, or do aphantasics have them but are simply unable to access them *consciously*?

Some researchers doubt that mental imagery could be completely absent, and have hypothesized that aphantasics who report having no conscious imagery at all might still have *unconscious* mental imagery [@nanay_unconscious_2020]. As this phenomenon is difficult to identify, little is known about unconscious mental imagery in aphantasia. A recent study by @liuProbingUnimaginableImpact2023 used a behavioural task to assess visual imagery in various domains (the French Perception-Imagination Battery) in aphantasics and controls. The task consisted of mentally comparing pairs of items based on various features (e.g. "beaver" - "fox": which is the *longest*?). They found no differences in accuracy between the groups, but slower RTs and lower confidence in the aphantasics' answers, and argued that this result was consistent with aphantasics having the visual images required [to succeed at the task, albeit without the knowledge of "how they did it"]{bg-colour="#FFFF00"}. Similarly, in a task that supposedly required visual imagery to verify whether a target dot was inside the boundaries of a previously presented geometric shape, @jacobsVisualWorkingMemory2018 found no difference in accuracy between an aphantasic participant and controls. As proposed by @nanay_unconscious_2020, this result could be interpreted as reflecting an unconscious comparison of a visual image with the stimuli perceived by the aphantasic participant. [Although on a N = 1 case study, this result may still suggest]{bg-colour="#FFFF00"} the existence of this unconscious form of imagery in aphantasia. However, due to the potential conscious processes at play in these behavioural tasks (with or without sensory imagery), neither study could completely rule out the hypothesis of aphantasics using strategies other than visual imagery (e.g. semantic processing, spatial imagery) to solve the tasks. This possibility, often raised in discussions about aphantasia [[e.g., @jacobsVisualWorkingMemory2018; @knightMemoryImageryNo2022; @liuProbingUnimaginableImpact2023; @monzelImagineYouWill2021]]{bg-colour="#FFFF00"}, prevents from firmly concluding from these results regarding the existence of unconscious mental images.

On the other hand, several studies that sought to develop objective measures assessing visual imagery found [consistent behavioural and physiological differences between aphantasics and controls on imagery tasks, thus challenging Nanay's (2020) hypothesis of unconscious mental imagery in aphantasia [see also @blomkvistAphantasiaSearchTheory2022].]{bg-colour="#FFFF00"} Aphantasics have been shown to have a [reduced]{bg-colour="#FFFF00"} skin conductance response to frightening scenarios [@wickenCriticalRoleMental2021], a reduced automatic pupil dilatation in reaction to imagined bright stimuli [@kayPupillaryLightResponse2022], or a reduced priming by visual imagery [@keoghBlindMindNo2018], suggesting that aphantasics are truly unable to produce mental images. The latter priming paradigm developed by [@keoghBlindMindNo2018] is particularly often cited as a promising and relatively undemanding task for objectively identifying aphantasia, and has already been used for this purpose in several subsequent studies [e.g., @keoghAttentionDrivenPhantom2020; @changImagelessImageryAphantasia2023]. In their initial study, they investigated visual imagery in aphantasics and controls using a binocular rivalry paradigm: in this task, participants were cued either with the letter “R” (for red) or the letter “G” (for green) and had to imagine one of two images, respectively a red-horizontal Gabor or a green-vertical Gabor. After rating the vividness of their mental image, they were presented with both Gabors simultaneously, one in the left eye, the other in the right, and asked to say which colour they had seen first. Their results showed that the mental visualization of the Gabors influenced the colour seen in the binocular rivalry task for control participants, but not for aphantasics. The authors interpreted this absence of priming in aphantasia as a real inability to generate mental images, and not just as a lack of metacognition skills.

While these conclusions are convincing about [conscious]{bg-colour="#FFFF00"} imagery, they cannot yet rule out the hypothesis of unconscious mental imagery. A first caveat in this study is that self-diagnosed aphantasics were explicitly asked to *voluntarily* form mental images and rate their vividness during the task. This aspect of their paradigm may have skewed the results from the start, as aphantasics were asked to do something they knew (or believed) they could not do in the first place. It is possible, then, that participants did not fully engage with the task - or did not perform it correctly - because they firmly believed that they would fail to comply with the instructions, due to the awareness of their aphantasia [see @cabbaiInvestigatingRelationshipsTrait2023 for evidence on demand biases in aphantasia]. Secondly, by using explicit priming, their study could not account for potential unconscious mental imagery, which is typically investigated with implicit priming tasks. Consequently, the binocular rivalry paradigm developed by [@keoghBlindMindNo2018; like other objective measures based on explicit instructions to use mental imagery, e.g., @kayPupillaryLightResponse2022; @miltonBehavioralNeuralSignatures2021] cannot exclude the possible existence of [unconscious]{bg-colour="#FFFF00"} mental images in aphantasia. We aimed to fill this gap by designing an implicit priming task that would allow us to study unconscious mental images in aphantasia.

## The present study {.unnumbered}

The objective of this study was to develop a new task inspired by the binocular rivalry used by @keoghBlindMindNo2018, including a priming task explicitly asking to use mental imagery, along with an implicit priming task specifically targeting unconscious mental imagery. Such a task would provide a novel and unprecedented behavioural method to identify the presence or absence of visual imagery and, by extension, to objectively characterize aphantasia.

To create an implicit task, the paradigm was divided into two parts: a prior association phase, and the implicit task itself. The association phase asked the participants to indicate the colour of a red horizontal Gabor or a blue vertical Gabor to implicitly memorize the colour-orientation association. In the subsequent implicit task, a red or blue coloured circle was presented as a prime before a target, which was a Gabor either congruent or incongruent with the colour seen (see @fig-protocol-asso and @fig-protocol-implicit in the Procedure section). As previous works of our team have shown [e.g., @brunelWhenSeeingDog2013; @reyMaskWhoWasn2015; @reyWhenReactivatedVisual2018], the prime is assumed to reactivate an unconscious mental image of the associated Gabor automatically. Participants were then asked to indicate the orientation of the target. An explicit task was added for control and comparison where participants were overtly asked to produce a mental image of the Gabors before the targets. In the explicit task, like in Keogh and Pearson’s study, participants were asked to imagine one of the previous Gabors by presenting a letter (R or B) as a cue. A Gabor congruent or incongruent with the colour was then presented as a target, and participants were asked to indicate the orientation of the lines of the target.

Shorter RTs in the congruent trials compared to the incongruent ones would therefore reflect an influence of unconscious mental images, helping participants to respond faster. Moreover, to ensure that any priming observed would be the consequence of mental imagery (as opposed to semantic priming, for example), in half of the trials the targets were presented in black and white rather in than colour. [If aphantasics have only difficulties with conscious mental imagery, a priming effect should be observed for both groups in the implicit task, but not in the explicit one. If aphantasics have difficulties with both conscious and unconscious mental imagery, no priming effect should be observed for the aphantasia group neither in the implicit nor in the explicit task, as opposed to the control group.]{bg-colour="#FFFF00"}

[In addition, we carried out a second analysis by defining "finer-grained" VVIQ sub-groups]{bg-colour="#FFFF00"}, with a subset of our sample composed solely of aphantasics with a minimal VVIQ score of 16, people with low imagery (VVIQ between 17 and 32), hereinafter called "hypophantasics" [using the terminology from @reederNonvisualSpatialStrategies2024], and controls (our sample included only two participants with VVIQ $>$ 75, so group analyses with hyperphantasics were not possible). This analysis aimed at answering a frequent interrogation in aphantasia literature about subgroups in aphantasia with differing characteristics: several authors pointed out that the fact of reporting *completely absent* imagery could be qualitatively very distinct from having only *vague* images [@blomkvistDefiningDiagnosingAphantasia2023; @dancePrevalenceAphantasiaImagery2022; @murakiInsightsEmbodiedCognition2023; @liuProbingUnimaginableImpact2023]. The object of our study, unconscious mental images, is a difficult phenomenon to reach, so this additional analysis could be crucial to judge the effects of our paradigm.

Finally, to assess the potential of this paradigm as a predictive tool for visual imagery ability, we performed correlations between the self-report questionnaires and the magnitude of the priming effect. If this effect is related to the generation of mental images, a clear association should arise between a greater priming effect and higher visual imagery ability.

# Methods

## Participants

We compared a group of self-identified aphantasic individuals with a control group of individuals with self-reported intact visual imagery. Participants were recruited from Facebook online community platforms dedicated to aphantasia in France using a recruitment ad. 151 participants completed the study. All completed an online version of the French Vividness of Visual Imagery Questionnaire [VVIQ-F, @santarpiaEvaluerVivaciteImages2008; adapted from @marksVividnessVisualImagery1973]: aphantasic participants were identified as the ones with a total VVIQ score below 32, which is the conventional threshold used in most studies on aphantasia [e.g., @danceWhatLinkMental2021; @danceWhatRelationshipAphantasia2021; @dawesCognitiveProfileMultisensory2020; @zemanLivesImageryCongenital2015]. 89 participants were in the aphantasic group ($M_{age} = 34.7, \ SD_{age} = 10.6, \ range_{age} = [19;59], \ M_{VVIQ} = 19.2, \ SD_{VVIQ} = 4.6, \ range_{VVIQ} = [16;31.5]$, 65 women) and 62 in the control group ($M_{age} = 33.2, \ SD_{age} = 9.7, \ range = [18;65], \ M_{VVIQ} = 54.5, \ SD_{VVIQ} = 12.3, \ range = [32;78.5]$, 31 women). All participants reported no lesions or acquired neurological or psychiatric disorders and no impaired or uncorrected vision.

The study was carried out following the recommendations of the French Law (Loi Jardé n◦2012- 300) with written informed consent being obtained from all the participants following the Declaration of Helsinki.

## Questionnaires

### Vividness of Visual Imagery Questionnaire - French adaptation (VVIQ-F)

The French version of the VVIQ [VVIQ-F, @santarpiaEvaluerVivaciteImages2008; adapted from @marksVividnessVisualImagery1973] used in this study was adapted in a Google Form version. It consists of sixteen items, each asking participants to imagine a particular scene and rate the vividness of their mental imagery using a Likert scale ranging from 1 ("No image at all, you only know that you are thinking about the object”) to 5 ("Perfectly clear and vivid as if it [were normal]{bg-colour="#FFFF00"} vision"). [The final score is ranging from 16 to 80.]{bg-colour="#FFFF00"}

### Spontaneous use of imagery scale (SUIS)

The French version of the SUIS [SUIS-F, @ceschiImagerieMentalePsychotherapie2018; adapted from @reisbergVisualMemoryWhen1986] used in this study was adapted in a Google Form version. It consists of 12 items, each asking participants to rate the degree to which a spontaneous use of mental imagery in a particular situation is appropriate to them using a Likert scale ranging from 1 (“Never appropriate”) to 5 (“Completely appropriate”). The final score is ranging from 12 to 60.

### Object and spatial imagery questionnaire (OSIQ)

The French version of the OSIQ [Dutriaux, unpublished, adapted from @blazhenkovaObjectspatialImageryNew2006] used in this study was adapted in a Google Form version. It consists of 30 items, half of the items (i.e., 15 items) are used to assess participants’ ability to imagine an object’s shape, texture, and colour (object imagery score), and the other half (i.e., 15 items) are used to assess participants’ ability to imagine location, movements, and spatial relationships (spatial imagery score). For each item, participants rate the degree to which they agree with the statement using a Likert scale ranging from 1 (“Totally disagree”) to 5 (“Totally agree”).

## Stimuli

### Gabor patterns

Four Gaussian-shaped Gabor patterns were generated: one red Gabor with horizontal lines and one blue Gabor with vertical lines (coloured Gabors); one black Gabor with horizontal lines and one black Gabor with vertical lines (uncoloured Gabors). All Gabor were superposed on a white 160 $\times$ 160 pixels background.

### Cues

Two cues were generated: a red circle and a blue circle. Both were of the same size as the Gabor patterns and were superposed on a white 160x160 pixels background.

## Software

The tasks were programmed using OpenSesame [@mathotOpenSesameOpensourceGraphical2012] and were uploaded on Jatos [@langeJustAnotherTool2015], a server used to run experiments online. All the experimental material is openly available on OSF (<https://osf.io/635dv/?view_only=72898c1e036c456b97e688629563a47f>).

## Procedure {#sec-procedure}

Participants were provided with two links, one directing to the experiments, and one directing to the questionnaire. They were instructed to perform the experiments and the questionnaires alone, in a quiet and not distracting environment, and to turn off their phones and other messaging devices. They were also asked to use a computer with a keyboard, as well as a good internet connection. Once participants clicked on the link to the experiments, the first experimental task launched.

![***Associative task.*** A fixation cross (500 ms) is followed by one of the two coloured Gabor. Participants had to indicate the colour of the Gabor by pressing the corresponding key (either R for Red or B for Blue), without time constraint. Each Gabor was presented 50 times.](../figures/protocol-asso.png){#fig-protocol-asso}

Participants began with the implicit priming task. This task began with an associative phase (@fig-protocol-asso) in which a fixation cross (500 ms) was followed by one of the two coloured Gabor, and participants had to indicate the colour of the Gabor by pressing the corresponding key (either R for Red or B for Blue), without time constraint. Each Gabor was presented 50 times. After the association phase, participants started the implicit priming test phase (@fig-protocol-implicit) in which a fixation cross (500 ms) was followed by a cue (150 ms) that was either a red or a blue circle, and then depending on the condition by either one of the two coloured Gabor or by one of the uncoloured Gabor, as a target. Participants had to indicate the orientation of the Gabor’s lines by pressing the corresponding key (either H for horizontal, or V for vertical), using only their dominant hand. In the congruent condition, the cue has the same colour as the target Gabor (coloured condition) or primed the Gabor with the same line orientation as the black target Gabor (uncoloured condition), contrary to the non-congruent condition. There were 16 trials per congruence and colour pairs, amounting to 64 trials total for the task. [Response mapping was not randomised due to the structure of the task: as there were as many congruent trials as incongruent ones, participants could not reliably predict the correct response based on the cue alone and a cue-response key association. Should they respond solely based on the key they associated with a cue, responses would be close to random, which could be easily spotted in the data. Consequently, learning a response key associated with a cue was not relevant and randomisation was not deemed necessary.]{bg-colour="#FFFF00"}

![***Implicit priming task.*** A fixation cross (500 ms) is followed by a cue (150 ms) that was either a red or a blue circle, and then by one of the two coloured Gabor, or by one of the uncoloured Gabor, as a target. Participants had to indicate the orientation of the Gabor’s lines by pressing the corresponding key (either H for horizontal, or V for vertical), using only their dominant hand.](../figures/protocol-implicit.png){#fig-protocol-implicit}

After the implicit priming task and a short break, participants transitioned to the explicit task (@fig-protocol-explicit) in which a fixation cross (500 ms) was followed by a letter as a cue (1500 ms) that was either the letter R (for red) or B (for blue). In response to the cue, participants were asked to form a mental imagery of the corresponding Gabor (a red with horizontal lines or a blue with vertical lines) and to keep that image in mind during 3000 ms while fixing the centre of a blank screen. Then, a fixation cross (500 ms) was presented followed by one of the two coloured Gabor, or by one of the uncoloured Gabor, and participants had to indicate the orientation of the Gabor’s lines by pressing the corresponding key (either H for horizontal, or V for vertical), using only their dominant hand. In the congruent condition, the cue designated the same colour as the target Gabor (coloured condition) or primed the Gabor with the same line orientation as the black target Gabor (uncoloured condition), contrary to the non-congruent condition. Likewise, there were 16 trials per congruence and colour pairs, amounting to 64 trials total for the task. It is worth mentioning that participants had practice trials at the beginning of each task and phase. Moreover, the implicit priming task was divided into two blocks, each beginning with the association phase, and ending with the implicit priming phase, to preserve the association between the colour of the Gabor and the orientation of its lines.

![***Explicit priming task.*** A fixation cross (500 ms) was followed by a letter as a cue (1500 ms) that was either the letter R (for red) or B (for blue). In response to the cue, participants were asked to form a mental imagery of the corresponding Gabor (a red with horizontal lines or a blue with vertical lines) and to keep that imagery in mind during 3000 ms while fixing the centre of a blank screen. Then, a fixation cross (500 ms) was presented followed by one of the two coloured Gabor, or by one of the uncoloured Gabor, and participants had to indicate the orientation of the Gabor’s lines by pressing the corresponding key (either H for horizontal, or V for vertical), using only their dominant hand.](../figures/protocol-explicit.png){#fig-protocol-explicit}

## Analyses

The data analysis was programmed in R language [version 4.2.0, @r2022] on RStudio [@rstudio2023]. The raw data, code, and analysis outputs are available on OSF (<https://osf.io/635dv/?view_only=72898c1e036c456b97e688629563a47f>).

### Self-report questionnaires

The scores of the four questionnaires were modelled with linear models on ranked scores to accommodate the ordinal nature of the questionnaire data and to control for the influence of age on the group differences. The models included the *Group* as a categorical predictor and the *Age* as a continuous co-variate. For group differences, we report estimated means, their standard errors, and two-tailed *p*-values of marginal contrasts between means, computed using a Wald *t*-distribution approximation.

### Outlier detection procedure

We excluded data from five participants that exceeded 43% of errors (therefore with too few trials to analyze). Trials with RTs abnormally fast or slow ($<$ 250ms or $>$ 3s, 1% and .7% respectively) that could represent false alarms (especially given the internet-based nature of the task) were removed. Participants with an aberrant RT average exceeding the median $\pm 3 \times$ MAD were excluded for each task [MAD proved to be more robust than standard deviations for outlier detection, see @leysDetectingOutliersNot2013]. The remaining data comprised N = 9082 trials for the implicit task and N = 8824 trials for the explicit task. For the analysis of reaction times (RTs), incorrect responses were also removed (2.7% and 3.6% of trials in the implicit/explicit task respectively). The remaining RT data comprised N = 8777 trials for the implicit and N = 8603 trials for the explicit task.

### [Accuracy]{bg-colour="#FFFF00"}

[Before removing incorrect responses for the analysis of response times, we first checked for any differences in accuracy between the groups.]{bg-colour="#FFFF00"} To this end, we fitted Generalized Logistic Mixed Models to predict accuracy with the *Group* (aphantasic, control), *Congruence* condition (congruent or incongruent), and *Colour* condition (colour or uncoloured) along with all their two and three-way interactions as fixed categorical predictors, while *participants* have been included as grouping factors (i.e. "random effects"). The models were implemented in the *lme4* R package [@bates2014fitting]. Overall fixed effects were assessed with Type II Wald $\chi^{2}$ tests using the *car* R package [@R-car].

### Response times

#### Power analysis

As the experiment was conducted online, the sample size was mostly limited by the time resources of the project. Likewise, the number of trials per condition and the total amount of trials were balanced in order not to overload the Internet experiment. From these two constraints, we estimated the statistical power conferred by the sample size eventually reached and the experimental design *a priori*, i.e. based on effect sizes reported in the literature and our hypotheses. We used the *simr* package [@greenSIMRPackagePower2016] to simulate datasets reflecting the experimental design, featuring expected patterns of means and variance, and fitting generalized linear mixed models on them.

Common effect sizes reported in the literature and intra-individual trial-to-trial variability in RTs in perceptual discrimination tasks have been used to simulate data and estimate the statistical power to detect effects tied to experimental conditions [for a similar procedure, see @fucciReadyHelpNo2023]. The main effect of interest chosen was the interaction between Group and Congruence, where we hypothesized a reduction in RTs for the control group in the congruent condition that would not be present in aphantasics. Simulations have shown that the statistical power reached 80% even with little effect sizes nearing 24ms, and exceeded 90% when the effect size went up and above 30ms. Details of the procedure can be found in an extended analysis report on OSF (<https://osf.io/635dv/?view_only=72898c1e036c456b97e688629563a47f>).

#### Generalized Linear Mixed Models

To account for the non-normal, positively skewed distributions of the RTs, we fitted Generalized Linear Mixed Models (GLMMs) with inverse Gaussian distributions, as recommended by @loTransformNotTransform2015. The models included the *Group* (aphantasic, control), *Congruence* condition (congruent or incongruent), and *Colour* condition (colour or uncoloured) along with all their two and three-way interactions as fixed categorical predictors, while *participants* have been included as grouping factors (i.e. "random effects"). Overall fixed effects were assessed with Type II Wald $\chi^{2}$ tests.

Due to the way that variance is partitioned in linear mixed models [@rightsQuantifyingExplainedVariance2019], there does not exist an agreed-upon way to calculate standard effect sizes for individual terms such as main effects or interactions in these models. Thus, in line with general recommendations on how to report effect sizes [e.g., @pekReportingEffectSizes2018], we report and analyse unstandardised effect sizes for post-hoc tests in the form of estimated marginal contrasts in milliseconds (i.e. differences in model-estimated marginal means, hereinafter denoted $\Delta$) where appropriate.

#### [Bayesian Modelling]{bg-colour="#FFFF00"}

To complement the frequentist approach, Bayesian hypothesis testing was also used to quantify the evidence in favour or against a congruence effect for each group. To this end, we fitted Bayesian multilevel models (analogous to the frequentist GLMMs presented above) separately for each group to predict RTs with the *Congruence* condition (congruent or incongruent), *Colour* condition (colour or uncoloured) and their two-way interaction as fixed categorical predictors, along with *participants* as grouping factors. Models were implemented in the *brms* R package [@burknerBrmsPackageBayesian2017]. The evidence ratio of interest was then computed as the Bayes Factor between the hypothesis of a congruence effect against the null hypothesis. We report the $BF_{01}$ in favour of the null hypothesis of an absence of congruence effect for a given group alongside the contrasts in the *Group* $\times$ *Congruence* interaction. The proposed interpretations of the strength of the evidence from Bayes Factor values were based on Jeffrey's scale thresholds [see e.g., @kassBayesFactors1995].

### [Finer-grained VVIQ groups]{bg-colour="#FFFF00"}

Additional analyses were conducted with more refined groups: the aphantasic group was restricted to participants scoring at the lowest point on the VVIQ (VVIQ = 16, N = 46), an "hypophantasic" group was created with participants scoring between 17 and 32 (N = 37), and the control group was restricted to participants scoring between 33 and 74 (N = 54). Our sample included only two "hyperphantasics" (VVIQ $\geq$ 75). These two participants were therefore removed from the analyses, as it was shown that hyperphantasics constitute a group with significant differences from typical imagers [see e.g., @miltonBehavioralNeuralSignatures2021; @zemanPhantasiaPsychologicalSignificance2020], but there were not enough of them in the present study to create such a group. Similar analyses to those carried out for the two initial groups were performed.

### Correlation analyses

[Spearman correlation coefficients were computed to assess the monotonic relationship between each questionnaire score and the *congruence effects* in both tasks.]{bg-colour="#FFFF00"} The congruence effect was computed for each participant as the difference between the mean RT in the incongruent condition minus the mean RT in the congruent condition, first averaging across colour conditions to account for this factor. Spearman correlations were chosen to relax the assumption of linearity of Pearson correlations, particularly given that the questionnaire variables are ordinal and that the data have an underlying group structure. [Correlations were also computed between the effects in both tasks.]{bg-colour="#FFFF00"} A False Discovery Rate (FDR) correction [@benjaminiControllingFalseDiscovery1995] was applied to the *p*-values to control for multiple comparisons.

# Results

## Self-report questionnaires

![Visualization of self-report questionnaires results for aphantasics and controls. Violin plots depict the distributions and quantiles of the scores in each group, median-centred on each scale. Coloured dots depict standardized means of the scores to the questionnaires, while the solid lines represent their standard errors. On the vertical axis, 0.0 is the normalized lowest possible score, 0.5 is the median score, and 1 is the maximum possible score for each questionnaire. Stars denote *p*-values inferior to .001 for each pairwise contrast between groups.](../figures/questionnaires.png){#fig-questionnaires}

As expected, aphantasic participants reported significantly less visual imagery across questionnaires (see @fig-questionnaires), scoring below controls on the VVIQ ($M_{Aph.}$ = 19.20 $\pm$ .47; $M_{Controls}$ = 54.39 $\pm$ 1.61; *t*(147) = 24.23, *p* $< .001$), the SUIS ($M_{Aph.}$ = 17.31 $\pm$ .44; $M_{Controls}$ = 37.07 $\pm$ 1.13; *t*(147) = 18.35, *p* $< .001$) and the object scale of the OSIQ ($M_{Aph.}$ = 23.90 $\pm$ .65; $M_{Controls}$ = 46.50 $\pm$ 1.52; *t*(147) = 15.19, *p* $< .001$). Surprisingly, aphantasics scored significantly lower than controls on the spatial scale of the OSIQ ($M_{Aph.}$ = 40.98 $\pm$ .83; $M_{Controls}$ = 45.59 $\pm$ 1.10; *t*(147) = 3.41, *p* $< .001$), a result contrasting with previous studies having found no between-group differences on this scale [e.g., @dawesCognitiveProfileMultisensory2020; @keoghBlindMindNo2018]. Nevertheless, this difference is much less pronounced than in other questionnaires, and there are large variations on this scale in the aphantasic group (e.g., the lowest observed score is 27/75, while the highest is 61/75).

## Accuracy

The models did not reveal any difference in accuracy between the two groups, neither in the implicit task (Wald $\chi^{2}$ = 1.17, *p* = 0.28) nor in the explicit task (Wald $\chi^{2}$ = 1.57, *p* = 0.21). The only significant effect concerned the Colour condition, both in the implicit task (Wald $\chi^{2}$ = 6.37, *p* = 0.01) and in the explicit task (Wald $\chi^{2}$ = 18.96, *p* = 0.21). In both cases, participants were more likely to answer correctly in the coloured condition rather than in the uncoloured ones (implicit task uncoloured/coloured odds ratio = 0.73, 95% CI \[ 0.58, 0.92\], *z* = -2.63, *p* = .009; explicit task uncoloured/coloured odds ratio = 0.52, 95% CI \[ 0.39, 0.69\], *z* = -4.49, *p* $<$ .001). Elsewhere, in both tasks, the model did not reveal any main effects of Congruence (implicit: *p* = 0.59; explicit: *p* = 0.6), no Group $\times$ Congruence interaction (implicit: *p* = 0.58; explicit: *p* = 0.89), no Group $\times$ Colour interaction (implicit: *p* = 0.9; explicit: *p* = 0.43) and no Congruence $\times$ Colour interaction (implicit: *p* = 0.9; explicit: *p* = 0.29).

## Response times

### Implicit task

The model for the RTs in the implicit task yielded a significant main effect of Congruence (Wald $\chi^{2}$ = 8.6, *p* = 0.003) and a significant interaction between Group and Congruence (@fig-model-implicit; Wald $\chi^{2}$ = 8.58, *p* = 0.003). Post-hoc contrasts of marginal means showed that controls responded faster in the congruent condition ($\Delta$(controls RT congruent - incongruent) = -30ms, SE = 6ms, 95% CI \[ -40, -10\], *p* $< .001$), [with extreme evidence in favour of a congruence effect for the control group ($BF_{01} < .001$).]{bg-colour="#FFFF00"} The contrast analysis also shows that the faster response of controls was driving the main effect of Congruence, as aphantasics did not respond faster in the congruent condition ($\Delta$(aphantasics RT congruent - incongruent) = -2ms, SE = 5ms, 95% CI \[ -10, 10\], *p* = .73), [with strong evidence against a congruence effect for the aphantasia group ($BF_{01} = 14.12$).]{bg-colour="#FFFF00"} The model did not show any main effect of Group (*p* = .43) or colour (*p* = .51), no interaction between Group and colour (*p* = 0.96) or Congruence and colour (*p* = 0.14), and no three-way interaction (*p* = 0.23).

![Visualizations of the interactions between Group and Congruence in the implicit task. The left plot shows the full range of mean response times; the right plot is a zoomed version on the marginal means to see the details of the effect sizes. The central coloured dots in both plots indicate the marginal means of the groups in each condition whereas the black bars represent the standard error of these estimates. On the left plot, the mean response times of each participant in the two conditions are represented as smaller coloured dots connected by a line to illustrate the individual congruence effects.](../figures/model-implicit.png){#fig-model-implicit}

### Explicit task

The model for the RTs in the explicit task yielded a significant main effect of Congruence (Wald $\chi^{2}$ = 14.5, *p* $<$ .001) and Colour (Wald $\chi^{2}$ = 47.6, *p* $<$ .001). The model also revealed a significant interaction between Group and Congruence (@fig-model-explicit; Wald $\chi^{2}$ = 10.7, *p* = 0.001). Post-hoc contrasts of marginal means showed that, once again, controls responded faster in the congruent condition ($\Delta$(controls RT congruent - incongruent) = -30ms, SE = 6ms, 95% CI \[ -40, -20\], *p* $< .001$), [with extreme evidence in favour of a congruence effect for the control group ($BF_{01} = .003$).]{bg-colour="#FFFF00"} Likewise, the faster response of controls was driving the main effect of Congruence, as aphantasics did not respond faster in the congruent condition either ($\Delta$(aphantasics RT congruent - incongruent) = -5ms, SE = 5ms, 95% CI \[ -20, 10\], *p* = .39), w[ith strong evidence against a congruence effect in the aphantasia group ($BF_{01} = 12.09$).]{bg-colour="#FFFF00"} The main effect of Colour reflects the fact that participants responded faster overall in the coloured condition ($\Delta$(RT coloured - uncoloured) = -30ms, SE = 4ms, 95% CI \[ -40, -20\], *p* $< .001$), although this factor did not interact with the two others. The model did not show any main effect of Group (*p* = .78), no interaction between Group and Colour (*p* = 0.37) or Congruence and Colour (*p* = 0.64), and no three-way interaction (*p* = 0.40).

![Visualizations of the interactions between Group and Congruence in the explicit task. The left plot shows the full range of mean response times; the right plot is a zoomed version on the marginal means to see the details of the effect sizes. The central coloured dots in both plots indicate the marginal means of the groups in each condition whereas the black bars represent the standard error of these estimates. On the left plot, the mean response times of each participant in the two conditions are represented as smaller coloured dots connected by a line to illustrate the individual congruence effects.](../figures/model-explicit.png){#fig-model-explicit}

## [Finer-grained VVIQ groups]{bg-colour="#FFFF00"}

### Self-report questionnaires

![Visualization of self-report questionnaires results for aphantasics, hypophantasics and controls. Violin plots depict the distributions and quantiles of the scores in each group, median-centred on each scale. Coloured dots depict standardized means of the scores to the questionnaires, while the solid lines represent their 95% CI. On the vertical axis, 0.0 is the normalized lowest possible score, 0.5 is the median score, and 1 is the maximum possible score for each questionnaire. \*: *p* $<$ .05; \**:* p\* $<$ .01; \*\*\*: *p* $<$ .001.](../figures/questionnaires-finer.png){#fig-questionnaires-finer}

The newly created hypophantasic group scored higher than the aphantasic group and lower than the control group on the VVIQ (see @fig-questionnaires-finer; $M_{Aph.}$ = 16; $M_{Hypo.}$ = 22.9 $\pm$ 1.1; $M_{Controls}$ = 53.49 $\pm$ 1; $\Delta$(Control-Hypo.) = 30.57, 95%CI \[27.37, 33.75\], *p* $< .001$, $\Delta$(Hypo.-Aph.) = 6.87, 95%CI \[3.54, 10.21\], *p* $< .001$) and SUIS ($M_{Aph.}$ = 16.1 $\pm$ 0.99; $M_{Hypo.}$ = 18.89 $\pm$ 1.1; $M_{Controls}$ = 36.98 $\pm$ 0.89; $\Delta$(Control-Hypo.) = 18.09, 95%CI \[15.28, 20.89\], *p* $< .001$, $\Delta$(Hypo.-Aph.) = 2.79, 95%CI \[-0.14, 5.72\], *p* $< .001$). The control group scored higher than the other two on the OSIQ-Object, however the hypophantasic group did not score higher than the aphantasic group ($M_{Aph.}$ = 23.04 $\pm$ 1.31; $M_{Hypo.}$ = 25.04 $\pm$ 1.48; $M_{Controls}$ = 46.09 $\pm$ 1.19; $\Delta$(Hypo.-Aph.) = 2, 95%CI \[-1.91, 5.91\], *p* = 0.31). On the OSIQ-Spatial, the control and hypophantasic group scored higher than the aphantasic group, but the control group did not score higher than the hypophantasic group ($M_{Aph.}$ = 39.46 $\pm$ 1.15; $M_{Hypo.}$ = 42.98 $\pm$ 1.3; $M_{Controls}$ = 45.47 $\pm$ 1.05; -$\Delta$(Control-Aph.) = 6.01, 95%CI \[2.93, 9.09\], *p* $< .001$; $\Delta$(Control.-Hypo.) = 2.49, 95%CI \[-0.80, 5.77\], *p* = 0.14; $\Delta$(Hypo.-Aph.) = 3.52, 95%CI \[0.09, 6.95\], *p* = 0.04).

### Implicit task

The new model for the implicit task showed a significant main effect of Congruence (Wald $\chi^{2}$ = 8.7, *p* = 0.003) and a significant interaction between Group and Congruence (@fig-model-implicit-finer; Wald $\chi^{2}$ = 13.23, *p* = .001). Once again, the contrast analyses revealed that the effect of Congruence was driven by controls responding faster in the congruent condition ($\Delta$(controls RT congruent - incongruent) = -30ms, SE = 7ms, 95% CI \[-40, -10\], *p* $< .001$,[$BF_{01}$ = .004, extreme evidence in favour of a congruence effect]{bg-colour="#FFFF00"}), as opposed to aphantasics ($\Delta$(aphantasics RT congruent - incongruent) = -5ms, SE = 7ms, 95% CI \[ -20, 10\], *p* = 0.46, [$BF_{01}$ = 12.59, strong evidence against a congruence effect]{bg-colour="#FFFF00"}). Interestingly, the hypophantasic group fitted in between, with a trend effect of Congruence ($\Delta$(RT congruent - incongruent) = -10ms, SE = 8ms, 95% CI \[ -30, 0\], *p* = 0.07) [and inconclusive evidence for or against a congruence effect ($BF_{01}$ = 2.41).]{bg-colour="#FFFF00"} There were no main effects of Group (*p* = 0.49), Colour (*p* = .46), no interaction between Group and Colour (*p* = .54) or Congruence and Colour (*p* = .17), and no triple interaction (*p* = .42).

![Visualizations of the interactions between Group and Congruence in the implicit task with redefined groups. The coloured dots the indicate the marginal means of the groups in each condition whereas the black bars represent the standard error of these estimates.](../figures/model-implicit-finer.png){#fig-model-implicit-finer}

### Explicit task

The new model for the explicit task showed a significant main effect of Congruence (Wald $\chi^{2}$ = 11.43, *p* $<$ .001) and Colour (Wald $\chi^{2}$ = 44.05, *p* $<$ .001), along with a significant interaction between Group and Congruence (@fig-model-explicit-finer; Wald $\chi^{2}$ = 8.18, *p* = 0.017). The contrast analyses again showed that the effect of Congruence was driven by controls responding faster in the congruent condition ($\Delta$(controls RT congruent - incongruent) = -30ms, SE = 7ms, 95% CI \[-40, -20\], *p* $< .001$, [$BF_{01}$ $<$ .001, extreme evidence in favour of a congruence effect]{bg-colour="#FFFF00"}), while aphantasics did not ($\Delta$(aphantasics RT congruent - incongruent) = 5ms, SE = 7ms, 95% CI \[ -10, 20\], *p* = 0.46, [$BF_{01}$ = 11.78, strong evidence against a congruence effect]{bg-colour="#FFFF00"}). This time, however, hypophantasics were aligned with the aphantasic group and showed no congruence effect ($\Delta$(RT congruent - incongruent) = 4ms, SE = 8ms, 95% CI \[ -20, 10\], *p* = 0.65, [$BF_{01}$ = 9.81, substantial evidence against a congruence effect]{bg-colour="#FFFF00"}). Contrast analysis on the main effect of Colour showed that participants responded faster overall in the coloured condition ($\Delta$(RT coloured - uncoloured) = -30ms, SE = 5ms, 95% CI \[ -40, -20\], *p* $< .001$), although this factor did not interact with the two others. There were no main effects of Group (*p* = 0.98), no interaction between Group and Colour (*p* = 0.79) or Congruence and Colour (*p* = 0.62), and no triple interaction (*p* = 0.32).

![Visualizations of the interactions between Group and Congruence in the explicit task with redefined groups. The coloured dots the indicate the marginal means of the groups in each condition whereas the black bars represent the standard error of these estimates.](../figures/model-explicit-finer.png){#fig-model-explicit-finer}

## Correlations with the subjective questionnaires

+---------------------------------+-------------------+----------------------------+----------------+----------------------------+
|                                 | VVIQ              | OSIQ-Object                | OSIQ-Spatial   | SUIS                       |
+=================================+===================+============================+================+============================+
| Implicit task congruence effect | $\rho$ = **0.21** | $\rho$ **= 0.26**          | *r* = 0.05     | ***r*** **= .27**          |
|                                 |                   |                            |                |                            |
|                                 | *p* = $0.02^{*}$  | ***p*** **=** $0.003^{**}$ | *p* = .57      | ***p*** **=** $0.002^{**}$ |
+---------------------------------+-------------------+----------------------------+----------------+----------------------------+
| Explicit task congruence effect | $\rho$ = 0.08     | $\rho$ = 0.12              | $\rho$ = -0.02 | $\rho$ = 0.16              |
|                                 |                   |                            |                |                            |
|                                 | *p* = 0.43        | *p* = 0.19                 | *p* = 0.83     | *p* = 0.08                 |
+---------------------------------+-------------------+----------------------------+----------------+----------------------------+

: Matrix of the pairwise Spearman correlation coefficients $\rho$ between each questionnaire score and the congruence effect in both tasks. {#tbl-correlations}

Finally, Spearman correlations were computed to assess the monotonic relationship between the questionnaire scores and the *congruence effects* in both tasks. In the explicit task, the congruence effect was not correlated with the VVIQ (*p* = 0.43), the OSIQ-Object (*p* = 0.19), the OSIQ-Spatial (*p* = 0.43), or the SUIS (*p* = 0.43). [Interestingly, the congruence effect in the explicit task also did not correlate with the effect observed in the implicit task]{bg-colour="#FFFF00"} (*p* = 0.57). In the implicit task however, the congruence effect correlated with the VVIQ ($\rho$ = 0.21, 95% CI \[0.05, 0.37\], *p* = 0.02), the OSIQ-Object ($\rho$ = 0.26, 95% CI \[0.10, 0.40\], *p* = 0.003) and the SUIS ($\rho$ = 0.27, 95% CI \[0.11, 0.41\], *p* = 0.002), but no correlation with the OSIQ-Spatial ($\rho$ = 0.05, 95% CI \[-0.11, 0.21\], *p* = 0.57). All the pairwise correlations between the scores and the congruence effects in both tasks are presented in @tbl-correlations. The three significant correlations of the implicit task congruence effects with the VVIQ, OSIQ-Object and SUIS are represented in @fig-corr-plots.

![Visualizations of the correlation between the congruence effect (i.e. the mean difference between incongruent and congruent RTs) in the implicit task and the VVIQ, OSIQ-Object and SUIS ranked scores. Aphantasics are represented with blue triangles, and controls with orange dots. All the observations are connected with a thin line to their group mean, represented as a bigger symbol. The black regression line denotes the Spearman correlation between the scores and the effect, independently of groups, along with its confidence interval.](../figures/corr-plots.png){#fig-corr-plots}

# Discussion

The objective of the present study was to examine whether aphantasics could form mental images but could not access them consciously, or whether they presented a genuine deficit in the generation of mental images. To this end, we built and tested implicit and explicit priming paradigms on aphantasic and control participants. Analyses revealed striking evidence that the control group showed a consistent congruence effect in both tasks, whereas the aphantasic group did not. The intensive study of Gabors in a preliminary association should have facilitated the decision for Gabors congruent with the prime, as demonstrated in the control group, an effect that can be interpreted as the influence of an unconscious mental image of the studied Gabors. However, this effect was not observed in the aphantasic group. [This result was also present when adopting a more conservative definition of aphantasia by analysing groups restricted to aphantasics scoring at floor VVIQ. This result supports the hypothesis that aphantasics have difficulty generating both conscious and unconscious mental images, rather than only conscious ones.]{bg-colour="#FFFF00"}

## Towards an implicit objective assessment of aphantasia

The priming task developed in the present study proved to be efficient to discriminate between groups of visual imagery ability, both when implemented with explicit instructions to use imagery and when implemented with implicit priming. The explicit task with instructions to produce mental imagery was inspired by the binocular rivalry paradigm developed by @keoghBlindMindNo2018 and [produced a similar pattern of results showing an absence of priming in aphantasia with a different task, thus validating the effectiveness of priming tasks to evidence conscious mental imagery differences.]{bg-colour="#FFFF00"} However, the main aim of our study was to go one step further and develop a task that could evidence mental imagery differences *without* relying on instructions to produce it. Thus, the implicit priming task developed here was designed to target specifically unconscious mental imagery without giving participants instructions. The results of this task consistently followed the same pattern as the explicit task, lending credence to the hypothesis that the implicit task involved an unconscious form of mental imagery. [Moreover, an in-depth analysis of finer-grained groups dissociating "complete aphantasia" (VVIQ = 16) from "hypophantasia" (17 \< VVIQ \< 32) revealed striking differences that characterized the two sub-groups]{bg-colour="#FFFF00"}[^1]. While the complete aphantasia group showed no priming effect in either the implicit and explicit tasks, the hypophantasia group showed a mixed pattern, with traces of a priming effect in the implicit task but not in the explicit one. We propose to interpret this pattern of results as suggesting that aphantasics may differ fundamentally from hypophantasics in that they would have neither conscious nor unconscious imagery, while hypophantasics might retain some unconscious imagery, but without the ability to voluntarily generate conscious mental images (i.e., what was asked of them in the explicit task). [In light of these results, we propose that this novel online paradigm provides a foundation to develop implicit, objective behavioural assessments of visual imagery using a minimal setup, thereby opening new avenues for a large-scale, objective characterization of aphantasia.]{bg-colour="#FFFF00"}

[^1]: [We thank an anonymous reviewer for the suggestion of this crucial analysis.]{bg-colour="#FFFF00"}

[The correlations of the congruence effect in the implicit task with the VVIQ, OSIQ-Object scale and the SUIS corroborate the potential of our paradigm to assess individual differences in visual imagery. This relationship supports that implicit tasks may prove to be stable relative to various assessments of visual imagery, and encourages further investigation of such implicit effects on a real continuum to depart from group comparisons.]{bg-colour="#FFFF00"} Future work investigating implicit behavioural effects which are correlated with visual imagery and observed at a *by-participant* level will be crucial to further ascertain results on aphantasia and individual differences in mental imagery. Considering this result, we also argue that a wider diversity of psychometric questionnaires needs to be used along with efficient behavioural tasks when studying aphantasia, to better understand the complex construct that is mental imagery.

## Unconscious mental imagery and sensorimotor simulation

A main novelty of our paradigm is that participants were not instructed to produce any specific mental content in the implicit task, thus avoiding demand bias. [This design therefore relies on the assumption that the task would trigger an unconscious form of imagery for those capable of it. However, this raises the question of whether the concept of "unconscious" mental images is relevant. The concept was introduced in the field of research on aphantasia research by @nanay_unconscious_2020, but its ability to explain behavioural findings on aphantasia has been debated debated since [see e.g., @blomkvistAphantasiaSearchTheory2022; @krempelAphantasiaInvoluntaryImagery2024].]{bg-colour="#FFFF00"} These hypothetical unconscious mental images could neither be voluntarily produced by the participant nor consciously experienced, and are therefore by definition very hard to objectify. @murakiInsightsEmbodiedCognition2023 suggest that the idea of "unconscious mental images" could be likened to the concept of "sensorimotor simulation" developed in the field of embodied cognition research. A sensorimotor simulation is the re-creation of the states in which the individual's perceptual and motor systems were in a previous experience, as well as their emotional and introspective states [e.g., @barsalouGroundedCognition2008; @barsalouSimulationSituatedConceptualization2009; @dijkstraMechanismsEmbodiment2015; @milleSensMemoire2021; @versaceContentsLongtermMemory2009; @versaceActInIntegratedView2014; @versaceCognitionIncarneeCognition2018]. From this re-creation emerges a representation that can reach consciousness in the form of a mental image of an object, if the neurons in the perceptual and motor systems that were activated during confrontations with this object are reactivated in the current situation. In support of this hypothesis, @petilliDatadrivenComputationalModels2021 have shown using implicit priming tasks that verbal cues affected subsequent processing of target words with related visual properties, even when visual processing was neither requested nor required. Various cross-modal priming studies have shown that such cues could also influence behavioural responses based on other modalities [e.g., verbal cues influencing decision tasks on images or sounds, see @brunelSensoryNatureKnowledge2010; @reyMaskWhoWasn2015; @reyAutomaticVisualSimulation2017; @valletPerceptualNatureCrossModal2010]. Similarly, @amitAsymmetricalRelationshipVerbal2017 have provided evidence that feature representations are generated in visual cortices during verbal cues, even in decision tasks based on verbal processing. This evidence supports the idea that multi-modal sensory representations emerge in priming tasks and influence behaviour. [Consequently, following the association drawn by @murakiInsightsEmbodiedCognition2023 between sensorimotor simulation and unconscious mental images, our results provide evidence that the simulation of the visual properties of incoming information could be reduced or absent in aphantasia.]{bg-colour="#FFFF00"}

## Alternative strategies and forms of imagery

A recurrent challenge when studying aphantasia is that many tasks that are often considered to require visual imagery could also be solved by other non-visual strategies, such as the use of internal or covert verbalization @monzelMemoryDeficitsAphantasics2022. In that vein, it could be argued that our tasks could be completed using a verbal or propositional strategy based on the colour of the stimuli. For instance, in the association phase, participants may have used the propositional strategy of forming the abstract or semantic representation of an association between colour and line orientation of the Gabors (e.g., by internally repeating that "blue patches have vertical lines"). During the tasks, participants could then have used such a representation when a prime was presented, which may have facilitated their response when the target's colour was congruent with the colour of the prime. However, [our tasks have the advantage of making the use of this type of strategies more difficult to adhere to, thanks to a condition in which the targets are not coloured.]{bg-colour="#FFFF00"} As no semantic representations had been previously associated with uncoloured targets, a colour-based strategy was inappropriate for these stimuli. This type of strategy could even have been [counter-productive]{bg-colour="#FFFF00"}, which could explain slower response times in the uncoloured condition than in the coloured condition. Thus, the persistence of the interaction between group and congruence independently of the colour conditions supports the idea that our results can not be explained purely by the reliance on propositional strategies.

Curiously, the analysis of questionnaire data yielded a significant difference between aphantasics and controls in reported spatial imagery, assessed by the spatial scale of the OSIQ, contrasting with previous studies on aphantasia that used this questionnaire and found no between-group differences [@dawesCognitiveProfileMultisensory2020; @keoghBlindMindNo2018; @bainbridgeQuantifyingAphantasiaDrawing2021]. While this difference is hard to interpret on its own, it is worth noting that although significant, the difference in spatial imagery between the groups is much less pronounced than the difference observed on visual imagery scales. Large differences in spatial imagery ability also existed within the aphantasic group, hinting that this finding could be specifically tied to our sample and, more generally, that there could exist various sub-types in aphantasia characterized by their variable reliance on different forms of mental representations (e.g., spatial, [auditory]{bg-colour="#FFFF00"}, kinaesthetic). Nevertheless, it should be mentioned that our paradigm relied partially on spatial judgements (namely, orientation properties of items) that might be impacted by spatial imagery abilities. This hypothesis may also apply to a growing number of studies on aphantasia that used paradigms consisting in the detection of orientation changes of Gabor patches, thought to assess visual imagery or visual working memory [e.g., @changBehavioralPerformanceCortical2023; @keoghAttentionDrivenPhantom2020; @keoghBlindMindNo2018; @keoghVisualWorkingMemory2021; @knightMemoryImageryNo2022; @slinnVividnessVisualImagery2023 inter alia]. While our results did exhibit differing patterns between groups, future studies should still pay particular attention to this spatial imagery factor. On the one hand, this would require a more systematic investigation of spatial imagery, which has proved to have distinct characteristics from visual imagery in aphantasia [see @blazhenkovaTwoEyesBlind2019; @palermoCongenitalLackExtraordinary2022]. On the other hand, this entails that care should be taken to design tasks that target visual imagery as specifically as possible, manipulating item properties such as colour or shape while accounting for semantic and spatial properties of items [see e.g., @liuProbingUnimaginableImpact2023].

## Consequences on aphantasia

Finally, the functional implications of the differences in information processing found in aphantasia also need to be evaluated in the context of their "real-world" consequences. Aphantasics have demonstrated to live typical lives, most eloquently echoed by the fact that aphantasia often goes unnoticed for years [@zemanLivesImageryCongenital2015; @zemanPhantasiaPsychologicalSignificance2020]. [Furthermore, it has been shown that aphantasia does not meet the criteria of a pathological disorder [see @blomkvistDefiningDiagnosingAphantasia2023; @monzelNoGeneralPathological2023 for a discussion].]{bg-colour="#FFFF00"} Thus, the finding of reduced unconscious mental imagery (or sensorimotor simulation) in aphantasia may be best interpreted as showing that these processes might not play a crucial role as previously thought, for instance on conceptual processing [see e.g., @meteyardComingAgeReview2012; @pecherBoundariesGroundingAbstract2018]. Several recent studies even suggest that this attenuation of internal sensory representations in aphantasia could have positive consequences: @wickenCriticalRoleMental2021 showed that aphantasics exhibited dimmed electrophysiological responses to frightening scenarios; @keoghFewerIntrusiveMemories2023 used a laboratory model of PTSD and noted that aphantasics reported fewer intrusive memories when confronted with traumatic films; @konigsmarkGanzflickerExperienceHigh2021 demonstrated, using a rhythmic flicker paradigm to induce pseudo-hallucinations, that aphantasics experienced less anomalous percepts. In the present study we have brought evidence suggesting that aphantasics may simulate less sensory elements in their unconscious representations. The potential positive consequences of this reduction in sensory simulation in aphantasia is an interesting topic that deserves further research.

## Conclusion

[In sum, our findings provide evidence suggesting that "total" aphantasia (defined by a VVIQ score of 16) may not solely result from impaired metacognition but could indicate an underlying reduction in both conscious and unconscious mental imagery. Additionally, a trend in the results indicated that hypophantasia (i.e., reduced imagery, VVIQ scores between 17 and 32) may involve the presence of unconscious imagery, albeit without the capacity for voluntary imagery generation.]{bg-colour="#FFFF00"} The consistency of the congruence effect patterns obtained in both our implicit and explicit tasks for the control and aphantasic groups suggests that this priming paradigm provides a promising and reliable foundation for developing future behavioral tasks that objectively and implicitly characterize unconscious mental imagery, without depending on participant introspection.

# Data and code availability {.unnumbered}

All the materials and implementations of the questionnaires and tasks, the anonymised data, the analysis scripts, and in-depth analysis notebooks are all freely available on the Open Science Framework (<https://osf.io/635dv/?view_only=72898c1e036c456b97e688629563a47f>).

# Author contributions {.unnumbered}

**Conceptualization**: RP, EC, VR, CA, RV, GP. **Data curation**: RP, MD, VR. **Formal analysis**: MD. **Funding acquisition**: GP, EC. **Investigation**: VR, CA. **Methodology**: RP, EC, VR, CA, RV, GP. **Project administration**: GP, EC. **Resources**: VR, CA, GP. **Software**: MD. **Supervision**: GP, EC. **Visualization**: MD. **Writing - Original Draft Preparation**: RP, MD, EC, VR, GP. **Writing - Review & Editing**: All authors.

# Declaration of interest {.unnumbered}

None.

{{< pagebreak >}}

# References {.unnumbered}

::: {#refs}
:::

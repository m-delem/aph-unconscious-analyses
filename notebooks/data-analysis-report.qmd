---
title: "Data analysis report"
subtitle: "Are there unconscious visual images in aphantasia? Development of an implicit priming paradigm"

authors:
  - name: Maël Delem
    orcid: 0009-0005-8518-1991
    email: mael.delem@univ-lyon2.fr
    corresponding: true
  - name: Rudy Purkart
    orcid: 0000-0002-5491-9958
  - name: Eddy Cavalli
    orcid: 0000-0003-3944-1973
  - name: Virginie Ranson
  - name: Charlotte Andrey
  - name: Rémy Versace
    orcid: 0000-0002-4219-6617
  - name: Gaën Plancher
    orcid: 0000-0002-0178-6207

format: 
  docx:
    reference-doc: custom-reference-doc.docx
supptbl-cap-location: top

# filters:
  # - authors-block

bibliography: references.bib
csl: apa.csl
---

# Preliminary Set-up {.unnumbered}

The data for the analysis is retrieved from the file `data/aphantasia_priming_tidy_data_latest.xlsx`, which contains four sheets, containing the raw data, the data from the association, explicit, and implicit task respectively.

This analysis was conducted in R language on [RStudio](https://posit.co/download/rstudio-desktop/). This analysis report was written with [Quarto](https://quarto.org/).

The code generating all the computations, figures, tables, etc. can be found in the `data-analysis-report.qmd` Quarto file.

```{r}
#| label: setup
#| output: false
#| code-summary: "Packages"

# The package `librairian` will ease the package management with the "shelf" 
# function, which automatically: 
# 1) checks if a package is installed 
# 2) installs it if need be
# 3) loads the package like the "library()" function would.
if (!require("librarian")) install.packages("librarian")
library("librarian")

# now putting packages on our library's shelves:
shelf(
  # ─── data management ─────────────────
  readxl,         # importing xlsx
  
  # ─── modelling ───────────────────────
  lme4,           # mixed models
  emmeans,        # marginal estimates
  statmod,        # easystats dependency
  modelsummary,   # model reporting
  flextable,
  doParallel,     # parallel execution
  multilevelmod,  # multilevel modelling with lmer and tidymodels
  simr,           # simulation for power analysis
  
  # ─── bayesian ───────────────────────
  brms,           # bayesian models
  bayesplot,      # bayesian plots

  # ─── data visualization ──────────────
  ggpubr,         # publication plots
  
  # ─── essential package collections ───
  tidymodels,     # modelling framework
  easystats,      # data analysis framework
  tidyverse       # modern R ecosystem
)

# ─── Fixing a seed for reproducibility ───
set.seed(14051998)

# ─── Bayesplot theme ───
color_scheme_set("teal")

# ─── Global theme ───
theme_set(theme_modern(base_size = 14))
```

```{r}
#| label: importing-data
#| code-summary: Importing data

# Implicit task
df_implicit <- 
  read_excel(
    "data/aphantasia_priming_tidy_data_latest.xlsx",
    sheet = "data_implicit"
    )

# Explicit task
df_explicit <- 
  read_excel(
    "data/aphantasia_priming_tidy_data_latest.xlsx",
    sheet = "data_explicit"
    )

# Questionnaires
df_questionnaires <- 
  read_excel(
    "data/aphantasia_priming_tidy_data_latest.xlsx",
    sheet = "data_questionnaires"
    )
```

# Self-report questionnaires

We modelled the scores at each questionnaire with Generalized Linear Models (GLMs) to accommodate the non-normal distributions in the sample. To ensure the best fit to the data, we fitted models with Gaussian, Gamma and inverse Gaussian distributions and compared them with the AIC and BIC as indices of model quality. The quality checks of the optimal models selected, that used Gamma distributions, are displayed in @suppfig-vviq-model, @suppfig-suis-model, @suppfig-osiqo-model and @suppfig-osiqs-model. The summary of the estimated marginal means and post-hoc contrast analyses of between-group differences is presented in @supptbl-questionnaire-results and depicted in @suppfig-questionnaire-results.

```{r}
#| label: fitting-glm-questionnaires
#| code-summary: "Fitting GLMs on questionnaire scores with `tidymodels`"
#| eval: false

# ─── Defining a tidymodels "recipe" to prepare the data ───────────────────────
model_recipe_glm <-
  df_questionnaires |> 
  recipe() |> 
  # declaring scores as dependent variables
  update_role(vviq80, suis60, osiq_o75, osiq_s75, new_role = "outcome") |> 
  # declaring groups and age as independent variables
  update_role(aphantasia, age, new_role = "predictor")

# ─── Specifying models with various distributions to be compared ──────────────

# Gaussian distribution
glm_gaussian <-
  linear_reg() |> 
  set_engine(
    "glm",
    family = gaussian()
    )

# Gamma distribution
glm_gamma <-
  linear_reg() |> 
  set_engine(
    "glm",
    family = Gamma()
    )

# Inverse Gaussian distribution
glm_inverse <-
  linear_reg() |> 
  set_engine(
    "glm",
    family = inverse.gaussian()
    )

# Listing these models
model_specs_glm <- list(
  glm_gaussian = glm_gaussian,
  glm_gamma    = glm_gamma,
  glm_inverse  = glm_inverse
)

# ─── Formulas for each questionnaire model ────────────────────────────────────
formula_q1 <-   vviq80 ~ aphantasia*age
formula_q2 <-   suis60 ~ aphantasia*age
formula_q3 <- osiq_o75 ~ aphantasia*age
formula_q4 <- osiq_s75 ~ aphantasia*age

# Listing these formulas
model_formulas_glm <- list(
  formula_q1 = formula_q1,
  formula_q2 = formula_q2,
  formula_q3 = formula_q3,
  formula_q4 = formula_q4
)

# ─── Table to combine everything in workflows and fit the models ──────────────

model_all_glm_fitted <-
  tribble(   ~recipe,          ~model,           ~formula,
    model_recipe_glm, model_specs_glm, model_formulas_glm
  ) |> 
  # combining recipes with models
  unnest_longer(model) |> 
  # combining them with formulas
  unnest_longer(formula) |>
  rowwise() |>
  mutate(
    # fitting models
    fitted_model = list(
      workflow() |>
      add_recipe(recipe) |> 
      add_model(model, formula = formula) |> 
      fit(df_questionnaires) |> 
      extract_fit_engine()
      )
  ) |> 
  select(!c(recipe, model, formula)) |>
  mutate(
    parameters = list(model_parameters(fitted_model)),
    model_perf = list(model_performance(fitted_model)),
    AICc  = model_perf[[2]]
  ) |> 
  select(!c(model_perf)) |> 
  arrange(formula_id)
```

```{r}
#| label: running-model-checks-vviq
#| eval: false
#| code-summary: "Running model checks"

# loading the model saved after the analysis
model_vviq <- readRDS(file = "analyses-results/model-vviq.RDS")

# plotting
model_vviq |> check_model(check = "all")
```

![Model assumption checks for the Generalized Linear Model fit on the VVIQ scores.](plots/glm-vviq-checks.png){#suppfig-vviq-model}

```{r}
#| label: running-model-checks-suis
#| eval: false
#| code-summary: "Running model checks"

# loading the model saved after the analysis
model_suis <- readRDS(file = "analyses-results/model-suis.RDS")

# plotting
model_suis |> check_model(check = "all")
```

![Model assumption checks for the Generalized Linear Model fit on the SUIS scores.](plots/glm-suis-checks.png){#suppfig-suis-model}

```{r}
#| label: running-model-checks-osiqo
#| eval: false
#| code-summary: "Running model checks"

# loading the model saved after the analysis
model_osiq_o <- readRDS(file = "analyses-results/model-osiq-o.RDS")

# plotting
model_osiq_o |> check_model(check = "all")
```

![Model assumption checks for the Generalized Linear Model fit on the OSIQ-Object scores.](plots/glm-osiq-o-checks.png){#suppfig-osiqo-model}

```{r}
#| label: running-model-checks-osiqs
#| eval: false
#| code-summary: "Running model checks"

# loading the model saved after the analysis
model_osiq_s <- readRDS(file = "analyses-results/model-osiq-s.RDS")

# plotting
model_osiq_s |> check_model(check = "all")
```

![Model assumption checks for the Generalized Linear Model fit on the OSIQ-Spatial scores.](plots/glm-osiq-s-checks.png){#suppfig-osiqs-model}

```{r}
#| label: loading-rds-questionnaires
#| echo: false

model_vviq   <- readRDS(file = "analyses-results/model-vviq.RDS")
model_suis   <- readRDS(file = "analyses-results/model-suis.RDS")
model_osiq_o <- readRDS(file = "analyses-results/model-osiq-o.RDS")
model_osiq_s <- readRDS(file = "analyses-results/model-osiq-s.RDS")
```

::: {#supptbl-questionnaire-results}
```{r}
#| label: questionnaire-results-table
#| code-summary: "Generating the summary table of the model results"

# ─── Creating a function to extract all the information from a model ──────────
generate_model_summary <- 
  function(model, questionnaire_name){
    table_summary <-
      estimate_means(model, at = "aphantasia", p_adjust = "fdr") |> 
      select(!c(CI_low, CI_high)) |>
      mutate(across(c(Mean, SE), ~as.character(round(.x, digits = 2)))) |> 
      unite("Mean ± SE", Mean:SE, sep = " ± ") |> 
      pivot_wider(
        names_from = aphantasia,
        values_from = "Mean ± SE"
      ) |> 
      mutate(Questionnaire = questionnaire_name) |> 
      rename(
        "Aphantasics" = yes,
        "Controls" = no
      ) |> 
      select(Questionnaire, everything()) |> 
      bind_cols(
        estimate_contrasts(
          model, 
          contrast = "aphantasia", 
          p_adjust = "fdr")[,7:9]
      ) 
    
    return(table_summary)
}

# ─── Merging the resulting tables of each questionnaire ───────────────────────
table_vviq   <- generate_model_summary(model_vviq,   "VVIQ")
table_suis   <- generate_model_summary(model_suis,   "SUIS")
table_osiq_o <- generate_model_summary(model_osiq_o, "OSIQ-Object")
table_osiq_s <- generate_model_summary(model_osiq_s, "OSIQ-Spatial")

table_questionnaire_results <-
  bind_rows(
    table_vviq,
    table_suis,
    table_osiq_o,
    table_osiq_s
  )

# ─── Displaying ───────────────────────────────────────────────────────────────
table_questionnaire_results |> display()
```

Estimated marginal means (± standard errors) of the groups at each questionnaire and results of the post-hoc contrast analyses of between-group differences.
:::

```{r}
#| label: questionnaire-results-plot
#| code-summary: "Generating the standardized model plots"
#| eval: false

# ─── Standardized model refits for the plots ──────────────────────────────────
df_questionnaires_standard <-
  df_questionnaires |>
  mutate(
    vviq80   = as.numeric(scales::rescale(vviq80, 
                                          from = c(16, 80), 
                                          to = c(0, 1))),
    suis60   = as.numeric(scales::rescale(suis60, 
                                          from = c(12, 60), 
                                          to = c(0, 1))),
    osiq_o75 = as.numeric(scales::rescale(osiq_o75, 
                                          from = c(15, 75), 
                                          to = c(0, 1))),
    osiq_s75 = as.numeric(scales::rescale(osiq_s75, 
                                          from = c(15, 75), 
                                          to = c(0., 1)))
    )

model_recipe_glm_standard <-
  df_questionnaires_standard |> 
  recipe() |> 
  update_role(vviq80, suis60, osiq_o75, osiq_s75, new_role = "outcome") |> 
  update_role(aphantasia, age, new_role = "predictor")

model_specs_glm_standard<- list(glm_gaussian = glm_gaussian)

model_all_glm_fitted_standard <-
  tribble(            ~recipe,                   ~model,           ~formula,
    model_recipe_glm_standard, model_specs_glm_standard, model_formulas_glm
  ) |> 
  # combining recipes with models
  unnest_longer(model) |> 
  # combining them with formulas
  unnest_longer(formula) |>
  rowwise() |>
  mutate(
    # fitting models
    fitted_model = list(
      workflow() |>
      add_recipe(recipe) |> 
      add_model(model, formula = formula) |> 
      fit(df_questionnaires_standard) |> 
      extract_fit_engine()
      )
  ) |> 
  select(!c(recipe, model, formula)) |> 
  arrange(formula_id)

model_vviq_standard   <- model_all_glm_fitted_standard[[3]][[1]]
model_suis_standard   <- model_all_glm_fitted_standard[[3]][[2]]
model_osiq_o_standard <- model_all_glm_fitted_standard[[3]][[3]]
model_osiq_s_standard <- model_all_glm_fitted_standard[[3]][[4]]

# ─── Settings for the plot ────────────────────────────────────────────────────

# calculating marginal means and CIs
marginal_vviq   <- estimate_means(model_vviq_standard,   at = "aphantasia")
marginal_suis   <- estimate_means(model_suis_standard,   at = "aphantasia")
marginal_osiq_o <- estimate_means(model_osiq_o_standard, at = "aphantasia")
marginal_osiq_s <- estimate_means(model_osiq_s_standard, at = "aphantasia")
 
marginal_means <-
  marginal_vviq |> 
  mutate(variable = "vviq80") |> 
  bind_rows(marginal_suis   |> mutate(variable = "suis60")) |> 
  bind_rows(marginal_osiq_o |> mutate(variable = "osiq_o75")) |> 
  bind_rows(marginal_osiq_s |> mutate(variable = "osiq_s75"))

# dodge width for all the geoms
dw <- 1
# axis text size
txt <- 14
# legend text size
txt_legend <- 12

# ─── Plotting ─────────────────────────────────────────────────────────────────
df_questionnaires_standard |> 
  pivot_longer(
    cols = c(vviq80, suis60, osiq_o75, osiq_s75),
    names_to = "variable"
  ) |> 
  ggplot(aes(
    x = fct_relevel(variable, c("vviq80", "suis60", "osiq_o75", "osiq_s75")),
    y = value,
    fill = aphantasia,
    color = aphantasia
  )) +
  # accentuation of the median line at 0.5
  geom_hline(
    yintercept = .5,
    linetype = 1,
    color = "grey30",
    alpha = .2
  ) +
  # violin shapes for the distributions and quantiles
  geom_violin(
    position = position_dodge(dw),
    alpha = .1,
    draw_quantiles = c(.25, .5, .75)
    ) +
  # points for means and lines for CIs
  geom_pointrange(
    data = marginal_means,
    aes(
    x = fct_relevel(variable, c("vviq80", "suis60", "osiq_o75", "osiq_s75")),
    y = Mean,
    ymin = CI_low,
    ymax = CI_high,
    color = aphantasia
    ),
    size = .75,
    linewidth = 1,
    position = position_dodge(dw)
  ) +
  # star for significance
  annotate(
    geom  = "text",
    label = "*",
    color = "black",
    x = 1,
    y = .95,
    size  = 10 
    ) +
  # dotted line that separates the different questionnaires
  geom_vline(
    aes(xintercept = stage(variable, after_scale = 1.5)),
    linetype = 3
  ) +
  # star for significance
  annotate(
    geom  = "text",
    label = "*",
    color = "black",
    x = 2,
    y = .95,
    size  = 10 
    ) +
  # dotted line that separates the different questionnaires
  geom_vline(
    aes(xintercept = stage(variable, after_scale = 2.5)),
    linetype = 3
  ) +
  # star for significance
  annotate(
    geom  = "text",
    label = "*",
    color = "black",
    x = 3,
    y = .95,
    size  = 10 
    ) +
  # dotted line that separates the different questionnaires
  geom_vline(
    aes(xintercept = stage(variable, after_scale = 3.5)),
    linetype = 3
  ) +
  # star for significance
  annotate(
    geom  = "text",
    label = "*",
    color = "black",
    x = 4,
    y = .95,
    # vjust = .1,
    # hjust = 6,
    size  = 10 
    ) +
  # Aesthetics
  scale_color_okabeito(name = "Group:  ", labels = c(" Control   ", " Aphantasic")) +
  scale_fill_okabeito(name = "Group:  ", labels  = c(" Control   ", " Aphantasic")) +
  scale_x_discrete(
    name = "",
    labels = c("VVIQ", "SUIS", "OSIQ-Object", "OSIQ-Spatial")
  ) +
  scale_y_continuous(
    name = "Standardized score",
    breaks = breaks_pretty(8)
  ) +
  theme_modern() +
  theme(
    panel.grid.major.x = element_blank(),
    panel.grid.major.y = element_line(),
    axis.text.x  = element_text(size = txt),
    axis.title.y = element_text(size = txt),
    legend.title = element_text(size = txt_legend),
    legend.text  = element_text(size = txt_legend),
    legend.position = "top"
    )
```

![Visualization of self-report questionnaires results for aphantasics and controls. Violin plots depict the distributions and quantiles of the scores in each group, median-centered on each scale. Colored dots depict marginal means estimated by the models fitted on the scores, while the solid lines represent their 95% confidence intervals. On the vertical axis, 0 is the normalized lowest possible score, 0.5 the median score, and 1 the maximum possible score for each questionnaire. Stars denote *p*-values inferior to .001 for each pairwise contrast between groups.](plots/questionnaires.png){#suppfig-questionnaire-results}

# Response times

## Power analysis

### Rationale

We hypothesised that difference in reaction times (RT) between congruent and incongruent trials (the congruence effect) in the tasks would be modulated by the visual imagery ability of participants, and therefore that we would observe between-group differences in the magnitude of this effect. In a statistical model with categorical predictors, evidence in favour of our hypothesis would be provided by a significant two-way interaction between Group and Congruence condition. Estimating the statistical power to capture such an effect, given an experimental design, a sample size and an effect size, requires simulations from a model close to the one that will be used for the analysis of real data, as well as assumptions about the structure of data. The power estimation procedure requires 3 steps:

1.  Specifying the structure and coefficients of a generative model

2.  Generating a synthetic dataset using the generative model and an expected effect size

3.  Fitting the same model on the simulated data and test the statistical significance of the interaction of interest

Steps 2 and 3 are then repeated as many times as necessary to reach a desired precision of estimation. The proportion of synthetic datasets for which the effect of interest is significant is an estimation of power. Steps 2 and 3 can also be repeated for a range of effect sizes, if the expected effect size is not known exactly which is what we have done here. We detail and justify below every assumption made for the generative model.

### Generative model

In real datasets, the distributions of RTs are right-skewed and can be modelled with transformations using Gamma or inverse Gaussian distributions. However, such a modelling choice is only an approximation as RTs do not follow exactly any distribution of the exponential family for which generalized models can be fitted. It is difficult to evaluate the impact of such approximation on type I and type II errors. Thus, for power calculation, we generated normally distributed RT and modelled them with a regular mixed model, which simplifies the model parametrization as well as alleviates the computational burden.

The generative model has been created using the `simr` R package.

```{r}
#| label: generate-data
#| code-summary: "Creating a dataset following the structure of our data for the generative model"
#| eval: false

# First creating a dataframe with no response data, but whose structure reflects the dataset that will be collected. 

# vectors for subjects
id <- seq(1:150)
groups <- rep(c("aphantasia", "control"), 75)

# conditions
congruences <- list("congruent", "incongruent")
colors <- list("colored", "uncolored")
# repeated 4 times each
congruence = rep(congruence, 4)
color = rep(colors, 4)

# creating the simulation df
df <- 
  tibble(
    id = id, 
    group = groups,
    congruence = list(congruence),
    color = list(color)
    ) |> 
  # crossing conditions for 64 trials/subject total
  unnest_longer(congruence) |> 
  unnest_longer(color)
```

-   Fixed effects: We included the ***Group*** (aphantasic, control), ***Congruence*** condition (congruent or incongruent) and ***Color*** condition (color or uncolored) along with all their two and three way interactions as fixed categorical predictors. Regression coefficients were set in such a way as to produce a pattern of means roughly following our hypotheses, where the control group would be faster solely in the congruent condition.

::: {.content-hidden when-format="docx"}
`simr` requires regression coefficients in order to simulate data. The functions below transform a pattern of cell means to regressions coefficients of a linear model, using a simple trick: modelling a dataframe of hypothesized cell means, as if each of them was one noise-less observation of a combination of experimental factors, provides the desired coefficient estimates.
:::

```{r}
#| label: sim-regression-coefs
#| code-summary: "Creating regression coefficients through models"
#| eval: false

# creating dataframes of regression coefficients
extract_coefficients <- function(effectsize) {
  df_temp <- tribble(
          ~group,   ~congruence,       ~color,   ~y,
    "aphantasia",   "congruent",    "colored",  -30,
    "aphantasia",   "congruent",  "uncolored",    0,
    "aphantasia", "incongruent",    "colored",  -30, 
    "aphantasia", "incongruent",  "uncolored",    0,
       "control",   "congruent",    "colored", -30 - effectsize,
       "control",   "congruent",  "uncolored",   0 - effectsize,
       "control", "incongruent",    "colored",  -30,
       "control", "incongruent",  "uncolored",    0
  )
  
  lm_coef <- lm(y ~ (group + congruence + color)^3, data = df_temp)

  # Set numerical errors to 0
  coef(lm_coef)[abs(coef(lm_coef)) < 10^(-10)] <- 0
  
  # converting to ms upon return
  return(coef(lm_coef)/1000)
}
```

-   Random intercepts: We included a random intercept for participants with a standard deviation of 150ms. This number was derived from the literature [see @fucciReadyHelpNo2023] - however, previous simulation studies have shown that the magnitude of random intercepts has no effect on statistical power whatsoever [@brysbaert], a result that we could verify in our own simulations.

-   Random slopes: We included random by-participant slopes for Congruence and Color, thus specifying the *full model* given our factors and resulting in the most conservative power estimates. Standard deviations of random slopes are virtually never reported in scientific publications; we set them at 50ms, which is in the same range as the maximum expected population-average effect size.

-   Correlations between random effects were all set to 0, but an alternative value (0.5) produced similar results.

This random effect structure has been specified and provided to a `simr` modelling function to simulate the models that will be fitted on our data.

```{r}
#| label: sim-random-effects 
#| code-summary: "Specifying the random effect structure and the final generative model"
#| eval: false

## Fixed effects: initialized at 0
fixed <- c(700,   # intercept
           0,0,0, # main effects
           0,0,0, # 2-way interactions
           0     # 3-way interactions
           )/1000

## Random intercepts for participants
v1 <- 0.150

## Random intercept, slopes (main effects only) and their covariances
slope  <- .05
correl <- 0
v2 <- matrix(
  c(1, correl, correl,
    correl, 1, correl,
    correl, correl, 1),
  3)

v2 <- cor_to_cov(v2, sd = c((v1), slope, slope))

## residual std dev
res <- .15

model <- makeLmer(
  formula = y ~ (group + congruence + color)^3 + (congruence + color|id),
  fixef   = fixed, 
  VarCorr = list(v2), 
  sigma = res,
  data  = df
  )
```

### Simulations

- Effect sizes: For the interaction Group x Congruence, the effect size can be defined as the double difference (aphantasics - controls) x (congruent - incongruent). Assuming, based on previous works, that the strongest difference would not exceed 50-60ms, and that differences below 10ms would hardly be meaningful, we ran simulations for differences between 10 and 60ms, by steps of 5ms. As the power reached the ceiling of 100% after 40ms effect sizes, we report here the results up to this size. 

- Number of simulations: For each effect size, we ran as many simulations as were needed to obtain a confidence interval below ±10 points around the mean. Going by steps of 50, we eventually ran 200 simulations for each effect size. These simulations ran for more than 8 hours, therefore their results are stored in `.RDS` R objects for ease of access: `analyses-results/power-analyses-list.RDS` and `analyses-results/power-analyses-table.RDS`. [They do not run automatically when rendering this `.qmd` file.]{.content-visible when-format="html"}

```{r}
#| label: simulations
#| code-summary: "Running the simulations for various effect sizes"
#| eval: false

# ─── Running simulations with parallel processing ─────────────────────────────

# finding the available cores for parallel processing
n_cores <- parallel::detectCores() - 1

# creating the cluster of cores
parallel_cluster <- 
  parallel::makeCluster(
    n_cores,
    type = "PSOCK"
  )

# registering the cluster for `foreach`
doParallel::registerDoParallel(cl = parallel_cluster)
# checking
# foreach::getDoParRegistered()
# foreach::getDoParWorkers()

# initializing, ready for takeoff
nsim <- 200

# Run calculations for a range of effect sizes
(simulations <-
  foreach(
    effectsize = c(10, 15, 20, 25, 30, 35, 40), 
    .packages = c("tidyverse", "simr")
    ) %dopar% {
      # Calculate regression coefficients corresponding to the effect size and 
      # update the model to simulate from accordingly
      fixef(model) <- extract_coefficients(effectsize)
      
      # Simulate data and estimate power
      powerSim(
        model, 
        nsim = nsim,
        test = simr::fixed(
          xname = "group:congruence", 
          method = 'anova'
          ))
    }) |> system.time() -> time_simulating

# stopping the cluster when we're done
parallel::stopCluster(cl = parallel_cluster)
```

### Results

The analysis yielded a power of 82% starting at effect sizes around 25ms, going up to 91% at 30ms and 97% at 35ms. Every effect size equal and above 40ms reached a ceiling of 100% power. The complete results are summarized in @supptbl-simulations-table and @suppfig-simulations-plot.

:::{#supptbl-simulations-table}
```{r}
#| code-summary: "Generating the summary table for the power analysis"

simulations_table <- 
  readRDS(file = "analyses-results/power-analyses-table.RDS")

simulations_table |> 
  # All the code below is simple formatting of the table that is in the RDS
  rename(
    "Effect size (difference in ms)" = effectsize,
    "Successes"   = successes,
    "Simulations" = trials,
    "Power" = mean
  ) |> 
  mutate(across(c(lower:upper), ~round(.x, digits = 2))) |> 
  unite("CI", lower:upper, sep = ", ") |> 
  mutate(CI = paste("[", CI, "]")) |> 
  rename("95% CI" = CI) |> 
  display()
```

Results of the power analysis through simulation.
:::

```{r}
#| label: simulations-plot
#| code-summary: "Generating the plot of the power analysis results"
#| eval: false

simulations_table |> 
  ggplot(aes(
    x = effectsize,
    y = mean,
    ymin  = lower,
    ymax  = upper,
    label = effectsize
    )) +
  # the band representing the 95% CIs
  geom_ribbon(fill = "aquamarine", alpha = .2) +
  # the means and CIs at each specific effect size
  geom_pointrange(colour = "aquamarine4") +
  geom_point(colour = "aquamarine4") +
  # line connecting the dots
  geom_line(colour = "aquamarine4") +
  # horizontal line at 80% power and corresponding annotation
  geom_hline(yintercept = .8, color = "black", linetype = 1) +
  annotate(
    geom  = "text",
    label = "80% power",
    fontface = "italic",
    color = "black",
    x = -Inf,
    y = .8,
    vjust = -.5,
    hjust = -.3,
    size  = 4 
    ) +
  # horizontal dotted line at 90% power and corresponding annotation
  geom_hline(yintercept = .9, color = "gray60", linetype = 2) +
  annotate(
    geom  = "text",
    label = "90% power",
    fontface = "italic",
    color = "grey60",
    x = -Inf,
    y = .9,
    vjust = -.5,
    hjust = -.3,
    size  = 4 
    ) +
  # Aesthetics
  scale_x_continuous(
    name = "Effect size (RT difference in ms)",
    breaks = unique(simulations_table$effectsize)
  ) +
  scale_y_continuous(
    name = "Statistical power",
    breaks = seq(0, 1, .1),
    limits = c(0, 1)
    ) +
  theme_modern() +
  theme(panel.grid.major = element_line())
```

![Results of the power analysis using simulations. 200 simulations have been computed for each effect size.](plots/power-analysis.png){#suppfig-simulations-plot}

## Outlier detection procedure {#sec-outliers}

:::{.content-visible unless-format="html"}
The code for the outlier detection procedure described in the manuscript can be found in the `data-analysis-report.qmd` file.
:::

:::{.content-visible when-format="html"}
Down below is the code for the outlier selection procedure described in the manuscript.
:::


```{r}
#| label: preparing-rt-data

# ═══ Accuracy outliers analysis ═══════════════════════════════════════════════

df_0e <- 
  df_explicit |> 
  mutate(across(c(aphantasia, color, congruence), as.factor))

df_0i <- df_implicit |> 
  mutate(across(c(aphantasia, color, congruence), as.factor))
```

```{r}
#| label: listing-error-rates
#| output: false

# ─── Listing error rates per subject ───
list(
  df_0e = df_0e,
  df_0i = df_0i
  ) |>
  imap(
    ~.x |>
      select(subjectid, starts_with("correct"), aphantasia) |>
      group_by(subjectid) |>
      count(pick(2)) |>
      filter(pick(1) == 1) |>
      ungroup() |>
      mutate(
        n_tot = max(n),
        prop = (n_tot - n) / n_tot * 100  # analyzing the error rate per subject
      ) %>%
      arrange(desc(prop)) |>
      select(1, 5)
    )
# 5 accuracy outliers in the explicit task, 4 in the implicit one
```

```{r}
#| label: removing-errors
#| output: false

# ─── Removing incorrect trials and task-wise accuracy outliers ───
df_1e_out <-
  df_0e |> 
  # filtering out...
  filter(
    # participants identified with with high error rates
    !(subjectid %in% c( 
      "subject_7",
      "subject_94", 
      "subject_25", 
      "subject_4",
      "subject_97"))
    ) |>  
  # removing irrelevant variables
  select(-c(sex, vviq80, orientation, response))

df_1i_out <-
  df_0i |> 
  filter(
    !(subjectid %in% c(
      "subject_21",
      "subject_56",
      "subject_9"
    ))
  ) |>  
  # removing irrelevant variables
  select(-c(sex, vviq80, orientation, response))

df_1e <-
  df_1e_out |> 
  # filtering out...
  filter(correct_explicit == 1) |> 
  select(!correct_explicit)

df_1i <-
  df_1i_out |> 
  # filtering out...
  filter(correct_implicit == 1) |> 
  select(!correct_implicit)
```

```{r}
#| label: removing-extreme-trials
#| output: false

# ═══ Broad RT outlier trials removal ════════════════════════════════════

df_2e <- 
  df_1e |>  
  # filtering out extreme RTs
  filter(rt > .3 & rt < 3)

df_2i <- 
  df_1i |>  
  # filtering out extreme RTs
  filter(rt > .3 & rt < 3)
```

```{r}
#| label: rt-means-table
#| output: false

# ═══ RT means table - Both tasks ══════════════════════════════════════════════

df_rt <- 
  list(df_2e = df_2e, df_2i = df_2i) |> 
  imap(
    ~.x |> 
      select(rt) |> 
      report() |>
      as.data.frame() |>  
      select(1:10)
  )
```

```{r}
#| label: detecting-aberrant-means
#| output: false

# ═══ Aberrant RT means outliers removal ═══════════════════════════════════════

# ─── Finding outliers ───
threshold_e <- df_rt$df_2e$Median + 3*df_rt$df_2e$MAD
threshold_i <- df_rt$df_2i$Median + 3*df_rt$df_2i$MAD

df_2e |>
  group_by(subjectid) |>
  summarise(mean_rt = mean(rt)) |>
  ungroup() |>
  filter(mean_rt > threshold_e) |>
  arrange(desc(mean_rt))
# 7 outliers in the explicit task

df_2i |>
  group_by(subjectid) |>
  summarise(mean_rt = mean(rt)) |>
  ungroup() |>
  filter(mean_rt > threshold_i) |>
  arrange(desc(mean_rt))
```

```{r}
#| label: removing-aberrant-means
#| output: false

# ─── Removing specific outliers ───

df_3e <- 
  df_2e |> 
  filter(
    !(subjectid %in% c(
      "subject_49",
      "subject_59",
      "subject_107",
      "subject_100",
      "subject_73",
      "subject_106",
      "subject_119"
    ))
  )

df_3i <- 
  df_2i |> 
  filter(
    !(subjectid %in% c(
      "subject_49",
      "subject_107",
      "subject_30",
      "subject_120",
      "subject_127"
    ))
  )
```

```{r}
#| label: preparing-correlations-data
#| output: false

# ─── Preparing tables for correlation ───
congruence_effects_emm <-
  list(
      df_3e = df_3e,
      df_3i = df_3i
      ) |> 
  imap(
    ~.x |> 
      group_by(subjectid, congruence, color) |> 
      reframe(mean_rt = mean(rt)) |> 
      group_by(subjectid, congruence) |> 
      reframe(mean = mean(mean_rt)) |> 
      pivot_wider(
        names_from = congruence,
        values_from = mean
      ) |> 
      mutate(congruence_effect = uncongruent - congruent, .keep = "unused") |> 
      left_join(df_questionnaires[,c(1,5:8)], by = "subjectid") |> 
      ungroup()
    )
```

```{r}
#| label: filtering-extreme-groups
#| output: false

df_3ex <-
  df_3e |> 
  left_join(df_questionnaires[c(1,5)], by = "subjectid") |> 
  filter(vviq80 == 16 | vviq80 >= 46)

df_3ix <-
  df_3i |>
  left_join(df_questionnaires[c(1,5)], by = "subjectid") |> 
  filter(vviq80 == 16 | vviq80 >= 42)

df_3ix |> 
  group_by(subjectid, aphantasia) |> 
  count() |> 
  group_by(aphantasia) |> 
  count()
```

## Modelling

### Setting contrasts

```{r}
#| label: setting-contrasts

# ─── Setting contrasts ────────────────────────────────────────────────────────
contrasts(df_3e$aphantasia) <- contr.sum(2)
contrasts(df_3e$congruence) <- contr.sum(2)
contrasts(df_3e$color) <- contr.sum(2)
```


### Bayesian news

```{r}
#| label: parallel-setup

# finding the available cores for parallel processing
n_cores <- parallel::detectCores() - 1
```

#### Formula and priors

We used the `brms` R package to fit Bayesian models on the RT data. The package allows for the specification of priors for each parameter of the model. The prior for the intercept was set to a normal distribution with a mean of -0.3 (~0.74s in log-units) and a wide SD of 0. As we expected effect sizes to be inferior to 50ms, we chose weakly informative priors on the coefficients accordingly with normal distributions of mean -2 and wide SDs of 0.

```{r}
#| label: model-brm-formula-priors

brm_formula <- 
  bf(rt ~ aphantasia * congruence * color + (congruence + color | subjectid))
# brm_formula_e <- 
#   bf(rt ~ aphantasia * congruence * color + (1 | subjectid),
#      ndt   ~ (1 | subjectid))

# get_prior(brm_formula_e, data = df_3e, family = shifted_lognormal())

# these priors are weakly informative and were flexible enough to allow for 
# convergence on the (1 | subject) model with ndt per subject, or the
# (congruence + color | subject) model without ndt per subject
brm_priors <- c(
  prior(normal(0, 0.5),  class = b),
  prior(normal(-0.8, 0.5), class = Intercept),
  # prior(normal(-0.7, 0.5), class = Intercept, dpar = ndt),
  prior(normal(1, 0.5), class = ndt),
  prior(normal(0.3, 0.5), class = sd),
  # prior(normal(0.3, 0.5), class = sd, dpar = ndt),
  prior(normal(2, 0.5),   class = sigma)
  )
```

#### Explicit task

##### Prior predictive check

```{r}
#| label: model-brm-explicit-prior-fitting
#| eval: false

n_chains  <- 1

brm_model_priors_e <-
  brm(
    formula = brm_formula, 
    data = df_3e, 
    family = shifted_lognormal(),
    prior = brm_priors,
    chains = n_chains,
    cores  = n_chains,
    warmup = 1000,
    iter = 2000,
    seed = 140598,
    silent = 0,
    refresh = 1,
    file = "analyses-results/brm-explicit-model-priors.rds",
    file_refit = "on_change",
    sample_prior = "only"
    )

pp_check(
  brm_model_priors_e, 
  ndraws = 50, 
  group = "aphantasia",
  type = "dens_overlay_grouped"
  ) +
  scale_x_continuous(
    name = "RT (s)",
    expand = c(0, 0),
    limits = c(0, 3),
    breaks = breaks_pretty(8)
  )
```

##### Model fitting and checks

```{r}
#| label: model-brm-explicit-fitting
#| eval: false

# n_chains  <- 1  # for testing
n_chains  <- n_cores
# warmup <- 100
# iter   <- 200
warmup <- 2000
iter   <- 4200

# init_ndt  <- list(Intercept_ndt = -3)
# inits_ndt <- replicate(n_chains, init_ndt, simplify = FALSE)

brm_model_e <-
  brm(
    formula = brm_formula, 
    data = df_3e, 
    family = shifted_lognormal(),
    prior = brm_priors,
    chains = n_chains,
    cores  = n_chains,
    warmup = warmup,
    iter = iter,
    # init = inits_ndt,
    seed = 140598,
    silent = 0,
    refresh = 1,
    control = list(
      adapt_delta = 0.9,
      max_treedepth = 15
      ),
    # all parameters need to be saved for potential estimation (BFs)
    save_pars = save_pars(all = TRUE),
    file = "analyses-results/brm-model-explicit.rds",
    file_refit = "always"
    )

# 18m 54s for 4200 iterations, full model without ndt

conditional_effects(brm_model_e, effects = "aphantasia:congruence")

pp_check(
  brm_model_e, 
  ndraws = 50, 
  group = "aphantasia",
  type = "dens_overlay_grouped"
  ) +
  scale_x_continuous(
    name = "RT (s)",
    expand = c(0, 0),
    limits = c(0, 3),
    breaks = breaks_pretty(8)
  )
```

##### Model description

```{r}
#| label: model-brm-explicit-description
#| eval: false

summary(brm_model_e)
describe_posterior(brm_model_e, rope_range = c(-0.01, 0.01))
```

##### Model estimates and contrasts

```{r}
#| label: model-brm-explicit-estimate-means
#| eval: false

brm_model_e_e_emm <- 
  emmeans(
    brm_model_e, 
    ~ congruence | aphantasia,
    epred = TRUE
    ) 
# brm_model_e_e_emm |> contrast() 
brm_model_e_e_emm |> pairs()
```

#### Implicit task

##### Prior predictive check

```{r}
#| label: model-brm-formula-priors-2

brm_formula <- 
  bf(rt ~ aphantasia * congruence * color + (congruence + color | subjectid))
# brm_formula_e <- 
#   bf(rt ~ aphantasia * congruence * color + (1 | subjectid),
#      ndt   ~ (1 | subjectid))

# get_prior(brm_formula_e, data = df_3e, family = shifted_lognormal())

# these priors are weakly informative and were flexible enough to allow for 
# convergence on the (1 | subject) model with ndt per subject, or the
# (congruence + color | subject) model without ndt per subject
brm_priors <- c(
  prior(normal(0, 0.5),  class = b),
  prior(normal(-1, 0.5), class = Intercept),
  # prior(normal(-0.7, 0.5), class = Intercept, dpar = ndt),
  prior(normal(0.5, 0.5), class = ndt),
  prior(normal(0.3, 0.5), class = sd),
  # prior(normal(0.3, 0.5), class = sd, dpar = ndt),
  prior(normal(1.2, 0.5),   class = sigma)
  )
```

```{r}
#| label: model-brm-implicit-prior-fitting
#| eval: false

n_chains  <- 1

brm_model_priors_i <-
  brm(
    formula = brm_formula, 
    data = df_3i, 
    family = shifted_lognormal(),
    prior = brm_priors,
    chains = n_chains,
    cores  = n_chains,
    warmup = 1000,
    iter = 2000,
    seed = 140598,
    silent = 0,
    refresh = 1,
    file = "analyses-results/brm-implicit-model-priors.rds",
    file_refit = "on_change",
    sample_prior = "only"
    )

pp_check(
  brm_model_priors_i, 
  ndraws = 50, 
  group = "aphantasia",
  type = "dens_overlay_grouped"
  ) +
  scale_x_continuous(
    name = "RT (s)",
    expand = c(0, 0),
    limits = c(0, 3),
    breaks = breaks_pretty(8)
  )
```

##### Model fitting and checks

```{r}
#| label: model-brm-implicit-fitting
#| eval: false

# n_chains  <- 1  # for testing
n_chains  <- n_cores
# warmup <- 100
# iter   <- 200
warmup <- 2000
iter   <- 4200

# init_ndt  <- list(Intercept_ndt = -3)
# inits_ndt <- replicate(n_chains, init_ndt, simplify = FALSE)

brm_model_i <-
  brm(
    formula = brm_formula, 
    data = df_3i, 
    family = shifted_lognormal(),
    prior = brm_priors,
    chains = n_chains,
    cores  = n_chains,
    warmup = warmup,
    iter = iter,
    # init = inits_ndt,
    seed = 140598,
    silent = 0,
    refresh = 1,
    control = list(
      adapt_delta = 0.9,
      max_treedepth = 15
      ),
    # all parameters need to be saved for potential estimation (BFs)
    save_pars = save_pars(all = TRUE),
    sample_prior = "yes",
    file = "analyses-results/brm-model-implicit.rds",
    file_refit = "always"
    )

# 18m 54s for 4200 iterations, full model without ndt

conditional_effects(brm_model_i, effects = "aphantasia:congruence")

pp_check(
  brm_model_i, 
  ndraws = 50, 
  group = "aphantasia",
  type = "dens_overlay_grouped"
  ) +
  scale_x_continuous(
    name = "RT (s)",
    expand = c(0, 0),
    limits = c(0, 3),
    breaks = breaks_pretty(8)
  )
```

##### Model description

```{r}
#| label: model-brm-implicit-description
#| eval: false

summary(brm_model_i)
describe_posterior(brm_model_i, rope_range = c(-0.01, 0.01))
```

##### Model estimates and contrasts

```{r}
#| label: model-brm-implicit-estimate-means
#| eval: false

brm_model_i_emm <- 
  emmeans(
    brm_model_i, 
    ~ congruence | aphantasia,
    epred = TRUE
    ) 
brm_model_i_emm |> pairs()
```

### What was already there

To account for the non-normal, positively skewed distributions of the RTs, we fitted Generalized Linear Mixed Models (GLMMs) with inverse Gaussian distributions. The models were implemented in the `lme4` R package and integrated in `tidymodels` workflows using the package `multilevelmod`. Models with Gamma and Gaussian distributions were also fitted and compared with the AIC and BIC to ensure that we chose the best distribution available. 

The models included the ***Group*** (aphantasic, control), ***Congruence*** condition (congruent or incongruent) and ***Color*** condition (color or uncolored) along with all their two and three way interactions as fixed categorical predictors, while ***participants*** have been included as grouping factors (i.e. "random effects"). The random effect structure was chosen by fitting and comparing models with every possible combination of distribution and structure (intercept by participant, congruence or color, slope by participant on congruence and/or color) aiming for the best balance between goodness of fit and parsimony. Complex random-effects structures including various slopes on the factors failed to converge to stable and reliable estimates, hence the optimal models chosen included a single by-participant random intercept.

The complete `tidymodels` workflows coded to fit and compare all the models are presented in [the code sections down below]{.content-visible when-format="html"} [the `data-analysis-report.qmd` file]{.content-hidden when-format="html"}.

```{r}
#| label: modelling-workflow
#| output: false

# ─── Recipe for preprocessing ─────────────────────────────────────────────────
model_recipes_glmm <-
  list(
    recipe_2e = df_3e,
    recipe_2i = df_3i
    ) |> 
    imap(
      ~.x |>
        recipe() |> 
        update_role(rt, new_role = "outcome") |> 
        update_role(
          subjectid, age, aphantasia, color, congruence, 
          new_role = "predictor") |> 
        add_role(subjectid, new_role = "group")
      )


# ─── Models ───────────────────────────────────────────────────────────────────
spec_glmm_inverse <-
  linear_reg() |> 
  set_engine(
    "glmer",
    family = inverse.gaussian(link = "identity")
  )

spec_glmm_gamma <-
  linear_reg() |> 
  set_engine(
    "glmer",
    family = Gamma(link = "identity")
  )

spec_glmm_gauss <-
  linear_reg() |> 
  set_engine(
    "lmer"
  )

# Listing the models
model_specs_glmm <- list(
  spec_glmm_inverse = spec_glmm_inverse,
  spec_glmm_gamma = spec_glmm_gamma,
  spec_glmm_gauss = spec_glmm_gauss
  )

# ─── Formulas ──────────────────────────────────

formula_0 <- rt ~ (aphantasia + congruence + color)^3 + (1|subjectid)
formula_1 <- rt ~ (aphantasia + congruence + color)^3 + (congruence + color|subjectid)
formula_2 <- rt ~ (aphantasia + congruence + color)^3 + (congruence|subjectid) + (color|subjectid)

model_formulas <-
  list(
    formula_0 = formula_0,
    formula_1 = formula_1,
    formula_2 = formula_2
  )

# ─── Individual fitting function ──────────────────────────────────

fitting <- function(recipe, model, formula, df){
  fitted <- 
    workflow() |> 
    add_recipe(recipe) |> 
    add_model(
      spec    = model,
      formula = formula 
    ) |> 
    fit(df) |> 
    extract_fit_engine()
  
  return(fitted)
}

# ─── Workflows ──────────────

model_workflows <-
  tribble(     ~recipe,           ~model,       ~formula,
    model_recipes_glmm, model_specs_glmm, model_formulas
  ) |> 
  # combining recipes with models and formulas
  unnest_longer(model) |>
  unnest_longer(recipe) |> 
  unnest_longer(formula) |> 
  rowwise() |>
  mutate(
    # creating workflows
    workflow = list(
      workflow() |>
      add_recipe(recipe) |> 
      add_model(model, formula = formula)  
      )
  ) |> 
  # appending the dataframes
  bind_cols(
    tibble(
      df = list(
        # 3 x 3 dfs for the models fitted on the explicit data
        df_e = df_3e,
        df_e = df_3e,
        df_e = df_3e,
        # 3 x 3 dfs for the models fitted on the implicit data
        df_i = df_3i,
        df_i = df_3i,
        df_i = df_3i
        ) |> rep(3)
    )
  )
```

:::{.content-visible when-format="html"}
The following code allow to fit all the models in parallel. It is computationally heavy, so it is not re-run upon each rendering of the `data-analysis-report.qmd` file.

```{r}
#| label: parallel-workflows-fitting
#| eval: false

# finding the available cores for parallel processing
n_cores <- parallel::detectCores() - 1

# creating the cluster of cores
parallel_cluster <-
  parallel::makeCluster(
    n_cores,
    type = "PSOCK"
  )

# registering the cluster for `foreach`
doParallel::registerDoParallel(cl = parallel_cluster)

model_fitted$fitted <-
  foreach(
    workflow = model_workflows$workflow,
    df       = model_workflows$df,
    .combine = "c",
    .packages = c("tidymodels", "multilevelmod")
    ) %dopar% {
      model_fit <-
        list(
          workflow |>
          fit(data = df) |>
          extract_fit_engine()
          )

      return(model_fit)
    }

model_fitted$parameters <-
  foreach(
    fitted = model_fitted$fitted,
    .combine = "c",
    .packages = c("parameters")
    ) %dopar% {
      parameters <- list(model_parameters(fitted))
      return(parameters)
    }

model_fitted$parameters <-
  foreach(
    fitted = model_fitted$fitted,
    .combine = "c",
    .packages = c("parameters")
    ) %dopar% {
      parameters <- list(model_parameters(fitted))
      return(parameters)
    }

model_fitted$parameters <-
  foreach(
    fitted = model_fitted$fitted,
    .combine = "c",
    .packages = c("parameters")
    ) %dopar% {
      parameters <- list(model_parameters(fitted))
      return(parameters)
    }

model_fitted$interaction <-
  foreach(
    parameters = model_fitted$parameters,
    .combine = "c",
    .packages = c("tidyverse")
    ) %dopar% {
      interaction <- list(parameters |> slice(5))
      return(interaction)
    }

model_fitted$estimmeans <-
  foreach(
    fitted = model_fitted$fitted,
    .combine = "c",
    .packages = c("emmeans")
    ) %dopar% {
      estimmeans <- list(emmeans(fitted, specs = pairwise~congruence*aphantasia))
      return(estimmeans)
    }

model_fitted$contrasts <-
  foreach(
    fitted = model_fitted$fitted,
    .combine = "c",
    .packages = c("modelbased")
    ) %dopar% {
      contrasts <- list(estimate_contrasts(fitted, contrast = c("aphantasia", "congruence")))
      return(contrasts)
    }

# stopping the cluster when we're done
parallel::stopCluster(cl = parallel_cluster)
```
:::

```{r}
#| label: fitting-optimal-models
#| eval: false

# ─── Fitting the optimal models ───────────────────────────────────────────────
glmm_e <- fitting(
  recipe  = model_recipes_glmm$recipe_2e, 
  model   = spec_glmm_inverse, 
  formula = formula_0, 
  df = df_3e
  )

glmm_i <- fitting(
  recipe  = model_recipes_glmm$recipe_2i, 
  model   = spec_glmm_inverse, 
  formula = formula_0, 
  df = df_3i
  )
```

```{r}
#| label: loading-optimal-models
#| include: false

glmm_e <- readRDS("analyses-results/model-explicit.RDS")
glmm_i <- readRDS("analyses-results/model-implicit.RDS")
```

The quality checks of the optimal models selected, that used inverse Gaussian distributions, are displayed in @suppfig-implicit-checks and @suppfig-explicit-checks.

```{r}
#| label: running-model-checks-implicit
#| eval: false
#| code-summary: "Running model checks"

# characteristics to check
model_checks <- c("pp_check","homogeneity", "vif", "outliers", "qq", "reqq")

# plotting
glmm_i |> check_model(check = model_checks, detrend = FALSE)
```

![Model assumption checks for the Generalized Linear Mixed Model fit on the RTs in the implicit task.](plots/glmm-i-checks.png){#suppfig-implicit-checks}

```{r}
#| label: running-model-checks-explicit
#| eval: false
#| code-summary: "Running model checks"

# characteristics to check
model_checks <- c("pp_check","homogeneity", "vif", "outliers", "qq", "reqq")

# plotting
glmm_e |> check_model(check = model_checks, detrend = FALSE)
```

![Model assumption checks for the Generalized Linear Mixed Model fit on the RTs in the explicit task.](plots/glmm-e-checks.png){#suppfig-explicit-checks}

The performances and estimates of the models are displayed in @supptbl-glmm-i-summary and @supptbl-glmm-e-summary. The contrasts at each level of the Group and Congruence variables are displayed in @supptbl-glmm-i-contrasts and @supptbl-glmm-e-contrasts.

:::{#supptbl-glmm-i-summary}
```{r}
#| label: glmm-i-summary

glmm_i |> 
  model_performance() |> 
  display()

glmm_i |> 
  model_parameters() |> 
  display()
```

Performance and estimates of the GLMM fitted on the implicit task data.
:::

:::{#supptbl-glmm-e-summary}
```{r}
#| label: glmm-e-summary

glmm_e |> 
  model_performance() |> 
  display()

glmm_e |>
  model_parameters() |> 
  display()
```

Performance and estimates of the GLMM fitted on the explicit task data.
:::

:::{#supptbl-glmm-i-contrasts}
```{r}
#| label: glmm-i-contrasts

glmm_i |> 
  estimate_contrasts(
    contrast = c("aphantasia", "congruence"), 
    p_adjust = "none"
    ) |> 
  display()
```

Contrasts of between levels of the Group and Congruence factor in the implicit task. "Yes" designates the aphantasia group, "No" designates the control group.
:::

:::{#supptbl-glmm-e-contrasts}
```{r}
#| label: glmm-e-contrasts

glmm_e |> 
  estimate_contrasts(
    contrast = c("aphantasia", "congruence"), 
    p_adjust = "none"
    ) |> 
  display()
```

Contrasts of between levels of the Group and Congruence factor in the implicit task. "Yes" designates the aphantasia group, "No" designates the control group.
:::


## Extremal groups

The same modelling pipeline has been applied to a dataset restricted to participants scoring at floor VVIQ (VVIQ = 16) and controls scoring the highest at the VVIQ in the sample (VVIQ between 42 and 78). The quality checks of the optimal models selected, that used inverse Gaussian distributions, are displayed in @suppfig-implicit-x-checks and @suppfig-explicit-x-checks. The performances and estimates of the models are displayed in @supptbl-glmm-ix-summary and @supptbl-glmm-ex-summary. The contrasts at each level of the Group and Congruence variables are displayed in @supptbl-glmm-ix-contrasts and @supptbl-glmm-ex-contrasts.

```{r}
#| label: fitting-extreme-models
#| eval: false

# ─── Fitting the optimal models ───────────────────────────────────────────────
glmm_ex <- 
  glmer(
    data = df_3ex,
    family = inverse.gaussian(link = "identity"),
    formula = formula_0
  )

glmm_ix <- 
  glmer(
    data = df_3ix,
    family = inverse.gaussian(link = "identity"),
    formula = formula_0
  )
```

```{r}
#| label: loading-extreme-models
#| include: false

glmm_ex <- readRDS("analyses-results/model-explicit-x.RDS")
glmm_ix <- readRDS("analyses-results/model-implicit-x.RDS")
```

```{r}
#| label: running-model-checks-implicit-x
#| eval: false
#| code-summary: "Running model checks"

# characteristics to check
model_checks <- c("pp_check","homogeneity", "vif", "outliers", "qq", "reqq")

# plotting
glmm_ex |> check_model(check = model_checks, detrend = FALSE)
```

![Model assumption checks for the Generalized Linear Mixed Model fit on the RTs in the implicit task.](plots/glmm-ix-checks.png){#suppfig-implicit-x-checks}

```{r}
#| label: running-model-checks-explicit-x
#| eval: false
#| code-summary: "Running model checks"

# characteristics to check
model_checks <- c("pp_check","homogeneity", "vif", "outliers", "qq", "reqq")

# plotting
glmm_ex |> check_model(check = model_checks, detrend = FALSE)
```

![Model assumption checks for the Generalized Linear Mixed Model fit on the RTs in the explicit task.](plots/glmm-ex-checks.png){#suppfig-explicit-x-checks}

:::{#supptbl-glmm-ix-summary}
```{r}
#| label: glmm-ix-summary

glmm_ix |> 
  model_performance() |> 
  display()

glmm_ix |> 
  model_parameters() |> 
  display()
```

Performance and estimates of the GLMM fitted on the implicit task data.
:::

:::{#supptbl-glmm-ex-summary}
```{r}
#| label: glmm-ex-summary

glmm_ex |> 
  model_performance() |> 
  display()

glmm_ex |>
  model_parameters() |> 
  display()
```

Performance and estimates of the GLMM fitted on the explicit task data.
:::

:::{#supptbl-glmm-ix-contrasts}
```{r}
#| label: glmm-ix-contrasts

glmm_ix |> 
  estimate_contrasts(
    contrast = c("aphantasia", "congruence"), 
    p_adjust = "none"
    ) |> 
  display()
```

Contrasts of between levels of the Group and Congruence factor in the implicit task. "Yes" designates the aphantasia group, "No" designates the control group.
:::

:::{#supptbl-glmm-ex-contrasts}
```{r}
#| label: glmm-ex-contrasts

glmm_ex |> 
  estimate_contrasts(
    contrast = c("aphantasia", "congruence"), 
    p_adjust = "none"
    ) |> 
  display()
```

Contrasts of between levels of the Group and Congruence factor in the implicit task. "Yes" designates the aphantasia group, "No" designates the control group.
:::

## Visualisations

:::{.content-visible when-format="html"}
Down below is the code to reproduce the figures presented in the manuscript.
:::

:::{.content-hidden when-format="html"}
The code to reproduce the figures presented in the manuscript can be found in the `data-analysis-report.qmd` file.
:::

```{r}
#| label: plot-variables
#| eval: false

# ─── Setup variables for the plots ────────────────────────────────────────────

# dodge width for all the geoms
dw <- .75
# stat text size
st <- 7
# legend and axis text size
txt <- 18
title_size <- 20

# marginal means predictions
glmm_e_preds <- glmm_e |> estimate_means(at = c("aphantasia", "congruence"))
glmm_i_preds <- glmm_i |> estimate_means(at = c("aphantasia", "congruence"))

# overall means and medians
rt_mean_e <- df_3e$rt |> mean()
rt_mean_i <- df_3i$rt |> mean()
```

```{r}
#| label: plot-explicit
#| eval: false

p_glmm_e <-
  df_3e |>
  ggplot(aes(
    x = congruence,
    y = rt * 1000,
    color = aphantasia
  )) +
  # linear modelling of the differences
  geom_line(
    data = glmm_e_preds,
    aes(
      y = Mean * 1000,
      group = aphantasia
    ),
    position = position_dodge(width = dw),
    linewidth = 1.5,
    linetype = 1
  ) +
  # predicted means of the model
  geom_pointrange2(
    data = glmm_e_preds,
    aes(
      x = congruence,
      y = Mean * 1000,
      ymin = Mean * 1000 - SE * 1000,
      ymax = Mean * 1000 + SE * 1000,
      group = aphantasia
      ),
    color = "black",
    position = position_dodge(width = dw),
    size = 1,
    linewidth = .75,
    show.legend = FALSE
  ) +
  geom_point2(
    data = glmm_e_preds,
    aes(
      x = congruence,
      y = Mean * 1000,
      color = aphantasia
      ),
    position = position_dodge(width = dw),
    size = 5,
    show.legend = FALSE
  ) +
  coord_flip() +
  labs(
    title = "Explicit task",
    x = NULL,
    y = "Response time (ms)"
    ) +
  # coord_cartesian(
  #   ylim = c(680, 800)
  # ) +
  scale_y_continuous(breaks = breaks_pretty(10)) +
  scale_x_discrete(labels = c("Congruent", "Incongruent")) +
  scale_color_manual(name = "", labels = c(" Control   ", " Aphantasic"), values = c("#56B4E9", "#E69F00")) +
  # scale_color_okabeito(name = "", labels = c(" Aphantasic (VVIQ = 16)   ", " Control (VVIQ > 42)")) +
  theme_modern() +
  theme(
    plot.title = element_text(hjust = 0.5, size = title_size),
    panel.grid.major.y = element_blank(),
    panel.grid.major.x = element_line(),
    axis.title.y = element_text(size = txt),
    # axis.ticks.y = element_blank(),
    # axis.text.y = element_text(size = txt),
    legend.text = element_text(size = txt)
    )

# p_glmm_e
```

```{r}
#| label: plot-implicit
#| eval: false

p_glmm_i <-
  glmm_i_preds |>
  ggplot(aes(
    x = congruence,
    y = rt * 1000,
    color = aphantasia
  )) +
  # linear modelling of the differences
  geom_line(
    data = glmm_i_preds,
    aes(
      y = Mean * 1000,
      group = aphantasia
    ),
    position = position_dodge(width = dw),
    linewidth = 1.5,
    linetype = 1
  ) +
  # predicted means of the model
  geom_pointrange2(
    data = glmm_i_preds,
    aes(
      x = congruence,
      y = Mean * 1000,
      ymin = Mean * 1000 - SE * 1000,
      ymax = Mean * 1000 + SE * 1000,
      group = aphantasia
      ),
    color = "black",
    position = position_dodge(width = dw),
    size = 1,
    linewidth = .75,
    show.legend = FALSE
  ) +
  geom_point2(
    data = glmm_i_preds,
    aes(
      x = congruence,
      y = Mean * 1000,
      color = aphantasia
      ),
    position = position_dodge(width = dw),
    size = 5,
    show.legend = FALSE
  ) +
  coord_flip() +
  labs(
    title = "Implicit task",
    x = NULL,
    y = "Response time (ms)"
    ) +
  # coord_cartesian(
  #   ylim = c(.60, .69)
  # ) +
  scale_y_continuous(breaks = breaks_pretty(10)) +
  scale_x_discrete(labels = c("Congruent", "Incongruent")) +
  scale_color_manual(name = "", labels = c(" Control   ", " Aphantasic"), values = c("#56B4E9", "#E69F00")) +
  # scale_color_okabeito(name = "", labels = c(" Aphantasic (VVIQ = 16)   ", " Control (VVIQ > 42)")) +
  theme_modern() +
  theme(
    plot.title = element_text(hjust = 0.5, size = title_size),
    panel.grid.major.y = element_blank(),
    panel.grid.major.x = element_line(),
    axis.title.y = element_text(size = txt),
    # axis.text.x = element_text(size = txt),
    legend.text = element_text(size = txt)
    )

# p_glmm_i
```

``` {r}
#| label: plot-both
#| eval: false

p_glmms <-
  ggarrange(
    p_glmm_i,
    p_glmm_e,
    common.legend = TRUE,
    legend = "top",
    ncol = 2,
    align = "v"
  )

# p_glmms
```

```{r}
#| label: plot-variables-x
#| eval: false

# ─── Setup variables for the plots ────────────────────────────────────────────

# dodge width for all the geoms
dw <- .75
# stat text size
st <- 7
# legend and axis text size
txt <- 18
title_size <- 20

# marginal means predictions
glmm_ex_preds <- glmm_ex |> estimate_means(at = c("aphantasia", "congruence"))
glmm_ix_preds <- glmm_ix |> estimate_means(at = c("aphantasia", "congruence"))

# overall means and medians
rt_mean_ex <- df_3ex$rt |> mean()
rt_mean_ix <- df_3ix$rt |> mean()
```

```{r}
#| label: plot-explicit-x
#| eval: false

p_glmm_ex <-
  df_3ex |>
  ggplot(aes(
    x = congruence,
    y = rt * 1000,
    color = aphantasia
  )) +
  # linear modelling of the differences
  geom_line(
    data = glmm_ex_preds,
    aes(
      y = Mean * 1000,
      group = aphantasia
    ),
    position = position_dodge(width = dw),
    linewidth = 1.5,
    linetype = 1
  ) +
  # predicted means of the model
  geom_pointrange2(
    data = glmm_ex_preds,
    aes(
      x = congruence,
      y = Mean * 1000,
      ymin = Mean * 1000 - SE * 1000,
      ymax = Mean * 1000 + SE * 1000,
      group = aphantasia
      ),
    color = "black",
    position = position_dodge(width = dw),
    size = 1,
    linewidth = .75,
    show.legend = FALSE
  ) +
  geom_point2(
    data = glmm_ex_preds,
    aes(
      x = congruence,
      y = Mean * 1000,
      color = aphantasia
      ),
    position = position_dodge(width = dw),
    size = 5,
    show.legend = FALSE
  ) +
  coord_flip() +
  labs(
    title = "Explicit task",
    x = NULL,
    y = "Response time (ms)"
    ) +
  # coord_cartesian(
  #   ylim = c(680, 800)
  # ) +
  scale_y_continuous(breaks = breaks_pretty(10)) +
  scale_x_discrete(labels = c("Congruent", "Incongruent")) +
  scale_color_manual(name = "", labels = c(" Control   ", " Aphantasic"), values = c("#56B4E9", "#E69F00")) +
  # scale_color_okabeito(name = "", labels = c(" Aphantasic (VVIQ = 16)   ", " Control (VVIQ > 42)")) +
  theme_modern() +
  theme(
    plot.title = element_text(hjust = 0.5, size = title_size),
    panel.grid.major.y = element_blank(),
    panel.grid.major.x = element_line(),
    axis.title.y = element_text(size = txt),
    # axis.ticks.y = element_blank(),
    # axis.text.y = element_text(size = txt),
    legend.text = element_text(size = txt)
    )

# p_glmm_e
```

```{r}
#| label: plot-implicit-x
#| eval: false

p_glmm_ix <-
  glmm_ix_preds |>
  ggplot(aes(
    x = congruence,
    y = rt * 1000,
    color = aphantasia
  )) +
  # linear modelling of the differences
  geom_line(
    data = glmm_ix_preds,
    aes(
      y = Mean * 1000,
      group = aphantasia
    ),
    position = position_dodge(width = dw),
    linewidth = 1.5,
    linetype = 1
  ) +
  # predicted means of the model
  geom_pointrange2(
    data = glmm_ix_preds,
    aes(
      x = congruence,
      y = Mean * 1000,
      ymin = Mean * 1000 - SE * 1000,
      ymax = Mean * 1000 + SE * 1000,
      group = aphantasia
      ),
    color = "black",
    position = position_dodge(width = dw),
    size = 1,
    linewidth = .75,
    show.legend = FALSE
  ) +
  geom_point2(
    data = glmm_ix_preds,
    aes(
      x = congruence,
      y = Mean * 1000,
      color = aphantasia
      ),
    position = position_dodge(width = dw),
    size = 5,
    show.legend = FALSE
  ) +
  coord_flip() +
  labs(
    title = "Implicit task",
    x = NULL,
    y = "Response time (ms)"
    ) +
  # coord_cartesian(
  #   ylim = c(.60, .69)
  # ) +
  scale_y_continuous(breaks = breaks_pretty(10)) +
  scale_x_discrete(labels = c("Congruent", "Incongruent")) +
  scale_color_manual(name = "", labels = c(" Control   ", " Aphantasic (VVIQ = 16)"), values = c("#56B4E9", "#E69F00")) +
  # scale_color_okabeito(name = "", labels = c(" Aphantasic (VVIQ = 16)   ", " Control (VVIQ > 42)")) +
  theme_modern() +
  theme(
    plot.title = element_text(hjust = 0.5, size = title_size),
    panel.grid.major.y = element_blank(),
    panel.grid.major.x = element_line(),
    axis.title.y = element_text(size = txt),
    # axis.text.x = element_text(size = txt),
    legend.text = element_text(size = txt)
    )

# p_glmm_i
```

``` {r}
#| label: plot-both-x
#| eval: false

p_glmms_x <-
  ggarrange(
    p_glmm_ix,
    p_glmm_ex,
    common.legend = TRUE,
    legend = "top",
    ncol = 2,
    align = "v"
  )

p_glmms_x
```

![Visualizations of the interactions between Group and Congruence in the optimal models for both tasks. The colored dots indicate the marginal means of the groups in each condition whereas the black bars represent the standard error of these estimates. The stars represent *p*-values inferior to .001 in the contrast analyses.](plots/glmms-interaction.png){#suppfig-glmms-interaction}

![Visualizations of the interactions between Group and Congruence in the optimal models for both tasks with smaller groups at extreme ends of the VVIQ. The colored dots the indicate marginal means of the groups in each condition whereas the black bars represent the standard error of these estimates. The stars represent *p*-values inferior to .001 in the contrast analyses.](plots/glmms-x-interaction.png){#suppfig-glmms-x-interaction}

## Correlations

:::{.content-visible when-format="html"}
Down below is the code to reproduce the correlations and the associated figure presented in the manuscript.
:::

:::{.content-hidden when-format="html"}
The code to reproduce the correlations and the associated figure presented in the manuscript can be found in the `data-analysis-report.qmd` file.
:::

```{r}
#| label: correlation-tables
#| eval: false

correlation_tables <-
  congruence_effects_emm |> 
  imap(
    ~.x |> 
      select(!subjectid) |> 
      correlation::correlation(verbose = FALSE) |> 
      display()
  )

correlation_tables[[1]]
correlation_tables[[2]]
```


```{r}
#| label: plot-correlations
#| eval: false

p_osiq <-
  congruence_effects_emm[[2]] |> 
  mutate(aphantasia = if_else(vviq80 < 32, "yes", "no")) |> 
  rename("VVIQ Group" = aphantasia) |> 
  mutate("VVIQ Group" = ifelse(`VVIQ Group` == "yes", "Aphantasic", "Control")) |> 
  ggscatter(
    x = "osiq_o75",
    y = "congruence_effect",
    color = "VVIQ Group",
    palette = c("#E69F00", "#56B4E9"),
    shape = "VVIQ Group",
    # add = "reg.line"
    # conf.int = TRUE
    mean.point = TRUE,
    mean.point.size = 5,
    star.plot = TRUE,
    star.plot.lwd = .08
  ) +
  geom_smooth(
    aes(x = osiq_o75, y = congruence_effect), 
    method = "lm",
    color = "black",
    linewidth = 1
    
    ) +
  stat_cor(
    label.x = 42,
    label.y = .25,
    size = 6
    ) +
  labs(
    x = "OSIQ-Object",
    y = "Congruence effect"
  ) +
  theme(
    legend.title = element_text(size = 16),
    legend.text = element_text(size = 16),
    axis.title = element_text(size = 16)
  )

p_suis <-
  congruence_effects_emm[[2]] |> 
  mutate(aphantasia = if_else(vviq80 < 32, "yes", "no")) |> 
  rename("VVIQ Group" = aphantasia) |> 
  mutate("VVIQ Group" = ifelse(`VVIQ Group` == "yes", "Aphantasic", "Control")) |> 
  ggscatter(
    x = "suis60",
    y = "congruence_effect",
    color = "VVIQ Group",
    palette = c("#E69F00", "#56B4E9"),
    shape = "VVIQ Group",
    mean.point = TRUE,
    mean.point.size = 5,
    star.plot = TRUE,
    star.plot.lwd = .08
  ) +
  geom_smooth(
    aes(x = suis60, y = congruence_effect), 
    method = "lm",
    color = "black",
    linewidth = 1
    ) +
  stat_cor(
    label.x = 35,
    label.y = .25,
    size = 6
    ) +
  labs(
    x = "SUIS",
    y = "Congruence effect"
  ) +
  theme(
    legend.title = element_text(size = 16),
    legend.text = element_text(size = 16),
    axis.title = element_text(size = 16)
  )

petit_plot <- 
  ggarrange(
    p_osiq,
    p_suis,
    ncol = 2,
    common.legend = TRUE,
    legend = "bottom"
  )

# petit_plot
```

![Visualizations of the correlation between the congruence effect (i.e. the mean difference between incongruent and congruent RTs) in the implicit task and the OSIQ-Object and SUIS scores. Aphantasics are represented with orange dots, and controls with blue triangles. All the observations are connected with a thin line to their group mean, represented as a bigger symbol. The black regression line denotes the correlation between the scores and the effect, independently of groups, along with its confidence interval.](plots/correlations.png){#suppfig-correlations}

{{< pagebreak >}}

# References

:::{#refs}
:::

